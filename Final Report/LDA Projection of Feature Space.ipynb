{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/matthewashman/github/MasterProject2018')\n",
    "\n",
    "# Import necessary modules. Set settings. Import data.\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import pdb\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "X_train = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_train.pkl')\n",
    "X_validation = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_validation.pkl')\n",
    "X_augmented_01 = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_augmented_01.pkl')\n",
    "X_augmented_02 = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_augmented_02.pkl')\n",
    "X_augmented_03 = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_augmented_03.pkl')\n",
    "X_augmented_04 = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_augmented_04.pkl')\n",
    "X_test = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolate feature matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train])\n",
    "X_values = X.drop(['Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1).values\n",
    "X_info = X[['Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]\n",
    "\n",
    "X_test_values = X_test.drop(['Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1).values\n",
    "X_test_info = X_test[['Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalised and Unnormalised Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "lda = LDA(n_components=2)\n",
    "# X_values_normalised = preprocessing.scale(X_values)\n",
    "X_lda = pd.DataFrame(data = lda.fit_transform(X_values, X_info['Label']),\n",
    "                     columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "X_test_lda = pd.DataFrame(data = lda.transform(X_test_values),\n",
    "                          columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "\n",
    "\n",
    "final_df = pd.concat([X_lda, X_info.reset_index()], axis = 1)\n",
    "final_test_df = pd.concat([X_test_lda, X_test.reset_index()], axis=1)\n",
    "\n",
    "# final_df = pd.concat([final_df, final_test_df], axis=0)\n",
    "\n",
    "labels = ['2', '1','0']\n",
    "colors = ['r', 'orange', 'g']\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(10,5), dpi=80)\n",
    "\n",
    "for label, color in zip(labels[::-1], colors[::-1]):\n",
    "    idx_to_keep = (final_df['Label'].values == label)\n",
    "    plt.scatter(final_df.loc[idx_to_keep, 'principal component 1'], \n",
    "                final_df.loc[idx_to_keep, 'principal component 2'], \n",
    "                c = color, \n",
    "                edgecolor='k', \n",
    "                s = 50)\n",
    "\n",
    "    \n",
    "names = []\n",
    "for i, row in final_df.iterrows():\n",
    "    row_name = row['Type'] + row['Patient'] + ' ' + row['Channel'] + ' ' + row['Coupling Interval'] + ' ' + str(row['Label'])\n",
    "    names.append(row_name)\n",
    "    \n",
    "sc = plt.scatter(final_df['principal component 1'], final_df['principal component 2'],\n",
    "                 alpha=0,\n",
    "                 s=50)\n",
    "        \n",
    "annot = ax.annotate(\"\", xy=(0,0), xytext=(20,20),textcoords=\"offset points\",\n",
    "                    bbox=dict(boxstyle=\"round\", fc=\"w\"),\n",
    "                    arrowprops=dict(arrowstyle=\"->\"))\n",
    "\n",
    "annot.set_visible(False)\n",
    "\n",
    "def update_annot(ind):\n",
    "\n",
    "    pos = sc.get_offsets()[ind[\"ind\"][0]]\n",
    "    annot.xy = pos\n",
    "    text = \"{}\".format(\" \".join([names[n] for n in ind[\"ind\"]]))\n",
    "    annot.set_text(text)\n",
    "\n",
    "\n",
    "def hover(event):\n",
    "    vis = annot.get_visible()\n",
    "    if event.inaxes == ax:\n",
    "        cont, ind = sc.contains(event)\n",
    "        if cont:\n",
    "            update_annot(ind)\n",
    "            annot.set_visible(True)\n",
    "            fig.canvas.draw_idle()\n",
    "        else:\n",
    "            if vis:\n",
    "                annot.set_visible(False)\n",
    "                fig.canvas.draw_idle()\n",
    "\n",
    "# patient_type = 'ep'\n",
    "# patient = '15'\n",
    "# idx_to_keep = ((final_df['Type'] == patient_type) & (final_df['Patient'] == patient))\n",
    "# plt.scatter(final_df.loc[idx_to_keep, 'principal component 1'],\n",
    "#             final_df.loc[idx_to_keep, 'principal component 2'],\n",
    "#             c = 'b',\n",
    "#             edgecolor='k',\n",
    "#             marker = 'x',\n",
    "#             s = 55)\n",
    "                \n",
    "fig.canvas.mpl_connect(\"motion_notify_event\", hover)\n",
    "plt.legend(['Green', 'Amber', 'Red'], fontsize=12)\n",
    "plt.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "plt.ylabel('Principal Component 1', fontsize=12)\n",
    "plt.xlabel('Principal Component 2', fontsize=12)\n",
    "\n",
    "# Remove borders\n",
    "plt.gca().spines[\"top\"].set_alpha(0.0)    \n",
    "plt.gca().spines[\"bottom\"].set_alpha(0.3)\n",
    "plt.gca().spines[\"right\"].set_alpha(0.0)    \n",
    "plt.gca().spines[\"left\"].set_alpha(0.3)   \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DTW Distance\n",
      "P1: 0.5837390773019119\n",
      "P2: -0.3429096809952817\n",
      "\n",
      "Location of Maximum Energy\n",
      "P1: -0.07247514572378526\n",
      "P2: -0.7399973276089686\n",
      "\n",
      "Location of Maximum Energy 2\n",
      "P1: 0.3236261832217499\n",
      "P2: 0.20258915386639653\n",
      "\n",
      "Mean Absolute Value\n",
      "P1: -0.4089754922306581\n",
      "P2: -0.23049861410542788\n",
      "\n",
      "Mean Absolute Value 2\n",
      "P1: 0.1304578153982499\n",
      "P2: 0.33772968436530043\n",
      "\n",
      "Number of Peaks\n",
      "P1: 0.42056294912011066\n",
      "P2: -0.7410960717283047\n",
      "\n",
      "Number of Peaks 2\n",
      "P1: 0.3142409022458136\n",
      "P2: 0.026737126758190448\n",
      "\n",
      "Percentage Fractionation\n",
      "P1: -0.05456720229701112\n",
      "P2: 0.47490419117015825\n",
      "\n",
      "Percentage Fractionation 2\n",
      "P1: 0.21732504121574156\n",
      "P2: 0.6142329789821204\n",
      "\n",
      "Ratio Above 1xSTD\n",
      "P1: -0.25842731184368756\n",
      "P2: 0.2272972549338028\n",
      "\n",
      "Ratio Above 1xSTD 2\n",
      "P1: 0.5053477129132262\n",
      "P2: -0.5036757464906647\n",
      "\n",
      "Sample Entropy Around Max Energy\n",
      "P1: -0.08538732519168957\n",
      "P2: -0.03853981799095566\n",
      "\n",
      "Sample Entropy Around Max Energy 2\n",
      "P1: 0.36792731344062823\n",
      "P2: -0.3357333593438396\n",
      "\n",
      "Width of Maximum Energy\n",
      "P1: 0.4708296225112601\n",
      "P2: 0.780491862597242\n",
      "\n",
      "Width of Maximum Energy 2\n",
      "P1: 0.024660182931978192\n",
      "P2: -0.016231214424229756\n"
     ]
    }
   ],
   "source": [
    "feature_names = X.drop(['Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1).columns\n",
    "lda_scalings = lda.scalings_\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    print('\\n' + feature)\n",
    "    print('P1: ' + str(lda_scalings[i][0]))\n",
    "    print('P2: ' + str(lda_scalings[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Projection Including Augmented Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_augmented = X_augmented_03[(X_augmented_03['Augmented']==1)]\n",
    "X_aug_values = X_augmented.drop(['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1).values\n",
    "X_aug_info = X_augmented[['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "lda = LDA(n_components=2)\n",
    "\n",
    "X_lda = pd.DataFrame(data = lda.fit_transform(X_values, X_info['Label']),\n",
    "                     columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "X_aug_lda = pd.DataFrame(data = lda.transform(X_aug_values),\n",
    "                          columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "\n",
    "\n",
    "final_df = pd.concat([X_lda, X_info.reset_index()], axis = 1)\n",
    "final_aug_df = pd.concat([X_aug_lda, X_aug_info.reset_index()], axis=1)\n",
    "\n",
    "labels = ['2', '1','0']\n",
    "colors = ['r', 'orange', 'g']\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,5), dpi= 80)\n",
    "\n",
    "for label, color in zip(labels[::-1], colors[::-1]):\n",
    "    idx_to_keep = (final_df['Label'].values == label)\n",
    "    plt.scatter(final_df.loc[idx_to_keep, 'principal component 1'], \n",
    "                final_df.loc[idx_to_keep, 'principal component 2'], \n",
    "                c = color, \n",
    "                edgecolor='k', \n",
    "                s = 50,\n",
    "               alpha=0.6)\n",
    "    \n",
    "   \n",
    "plt.scatter(final_aug_df['principal component 1'].values, final_aug_df['principal component 2'].values,\n",
    "            c='r', \n",
    "            edgecolor='k',\n",
    "            s=50,\n",
    "            marker='v')\n",
    "\n",
    "\n",
    "plt.legend(['Green', 'Amber', 'Red', 'Augmented'], fontsize=12)\n",
    "plt.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "plt.ylabel('Principal Component 2', fontsize=12)\n",
    "plt.xlabel('Principal Component 1', fontsize=12)\n",
    "\n",
    "# Remove borders\n",
    "plt.gca().spines[\"top\"].set_alpha(0.0)    \n",
    "plt.gca().spines[\"bottom\"].set_alpha(0.3)\n",
    "plt.gca().spines[\"right\"].set_alpha(0.0)    \n",
    "plt.gca().spines[\"left\"].set_alpha(0.3)   \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.68264139e-01 -9.13386800e-02]\n",
      " [ 3.34413254e+00 -2.41011888e+01]\n",
      " [ 1.69076547e-01  2.76432731e-03]\n",
      " [ 4.30956109e-02  7.76008719e-02]\n",
      " [ 8.04937895e+00 -1.77550022e+01]\n",
      " [ 2.08168238e+00  2.46195723e+00]\n",
      " [ 5.40274171e-02  1.01810531e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(lda.scalings_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-82efafe70e32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnormalised_feature_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mfeature_values_lda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalised_feature_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m lda_df = pd.DataFrame(data = feature_values_lda,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_values' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn import preprocessing\n",
    "lda = LDA(n_components=2)\n",
    "normalised_feature_values = preprocessing.scale(feature_values.values)\n",
    "feature_values_lda = lda.fit_transform(normalised_feature_values, info['Label'])\n",
    "lda_df = pd.DataFrame(data = feature_values_lda,\n",
    "                      columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "final_df = pd.concat([lda_df, info.reset_index()], axis = 1)\n",
    "\n",
    "labels = ['2', '1','0']\n",
    "colors = ['r', 'orange', 'g']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "for label, color in zip(labels[::-1], colors[::-1]):\n",
    "    idx_to_keep = (final_df['Label'].values == label)\n",
    "    plt.scatter(final_df.loc[idx_to_keep, 'principal component 1']\n",
    "                   ,final_df.loc[idx_to_keep, 'principal component 2']\n",
    "                   ,c = color\n",
    "                   ,edgecolor='k'\n",
    "                   ,s = 50)\n",
    "   \n",
    "names = []\n",
    "for i, row in final_df.iterrows():\n",
    "    row_name = row['Type'] + row['Patient'] + ' ' + row['Channel'] + ' ' + row['Coupling Interval'] + ' ' + str(row['Label'])\n",
    "    names.append(row_name)\n",
    "    \n",
    "sc = plt.scatter(final_df['principal component 1'], final_df['principal component 2'],\n",
    "                alpha=0,\n",
    "                s=50)\n",
    "        \n",
    "annot = ax.annotate(\"\", xy=(0,0), xytext=(20,20),textcoords=\"offset points\",\n",
    "                    bbox=dict(boxstyle=\"round\", fc=\"w\"),\n",
    "                    arrowprops=dict(arrowstyle=\"->\"))\n",
    "\n",
    "annot.set_visible(False)\n",
    "\n",
    "def update_annot(ind):\n",
    "\n",
    "    pos = sc.get_offsets()[ind[\"ind\"][0]]\n",
    "    annot.xy = pos\n",
    "    text = \"{}\".format(\" \".join([names[n] for n in ind[\"ind\"]]))\n",
    "    annot.set_text(text)\n",
    "\n",
    "\n",
    "def hover(event):\n",
    "    vis = annot.get_visible()\n",
    "    if event.inaxes == ax:\n",
    "        cont, ind = sc.contains(event)\n",
    "        if cont:\n",
    "            update_annot(ind)\n",
    "            annot.set_visible(True)\n",
    "            fig.canvas.draw_idle()\n",
    "        else:\n",
    "            if vis:\n",
    "                annot.set_visible(False)\n",
    "                fig.canvas.draw_idle()\n",
    "                \n",
    "fig.canvas.mpl_connect(\"motion_notify_event\", hover)\n",
    "plt.legend(['Green', 'Amber', 'Red'], fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.title('LDA Projection of Features', fontsize=16)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A shitty conduction delay detector\n",
    "def get_delay(x, amp_thresh=None, set_thresh=False):\n",
    "    if (set_thresh==True):\n",
    "        if any(abs(x)>amp_thresh):\n",
    "            return np.argmax(abs(x)>amp_thresh)\n",
    "        else:\n",
    "            return len(x)\n",
    "    else:    \n",
    "        return np.argmax(abs(x)>(max(abs(x))/2))\n",
    "    \n",
    "def denoise(x):\n",
    "    # Obtain Daubechies N=6 wavelet coefficients\n",
    "    waveletCoefs = pywt.wavedec(x, 'db7', mode='per')\n",
    "\n",
    "    # Throw away coefficients corresponding to noise\n",
    "    sigma = mad(waveletCoefs[-1])\n",
    "    uThresh = 1*sigma*np.sqrt(2*np.log(len(x)))\n",
    "    denoised = waveletCoefs[:]\n",
    "    denoised[1:] = (pywt._thresholding.hard(i, value=uThresh) for i in denoised[1:])\n",
    "\n",
    "    # Reconstruct the original signal\n",
    "    xDenoised = pywt.waverec(denoised, 'db7', mode='per')\n",
    "\n",
    "    return xDenoised\n",
    "\n",
    "def get_peaks(x, height_thresh, scale_amp=None, set_scale=False, plot = False):\n",
    "    x = np.array(x)\n",
    "    \n",
    "    # Get height_thresh\n",
    "    if set_scale:\n",
    "        height_thresh = height_thresh*scale_amp\n",
    "    else:\n",
    "        height_thresh = height_thresh*max(abs(x))\n",
    "    \n",
    "    # Denoise x\n",
    "    xdn = denoise(x)\n",
    "\n",
    "    # Detect peaks using detect_peaks\n",
    "    pos_peak_idx = detect_peaks(xdn, mph=height_thresh, threshold = 0)\n",
    "    neg_peak_idx = detect_peaks((-xdn), mph=height_thresh, threshold = 0)\n",
    "    peak_idx = np.concatenate([pos_peak_idx, neg_peak_idx])\n",
    "    peak_idx = np.sort(peak_idx)\n",
    "    # Edge indeces aren't detected\n",
    "    peak_idx = peak_idx[(peak_idx != 0) & (peak_idx != (len(xdn)-1))]\n",
    "\n",
    "    new_peak_idx = []\n",
    "    peak_amp = []\n",
    "    if (len(peak_idx) > 0):\n",
    "        new_peak_idx.append(peak_idx[0])\n",
    "        mp_thresh = 0.2*max(abs(x))\n",
    "        for i in range(len(peak_idx)-1):\n",
    "            idx = peak_idx[i]\n",
    "            idx_next = peak_idx[i+1]\n",
    "            mid_point = int((idx_next+idx)/2)\n",
    "            if (max([abs(x[idx_next]-x[mid_point]), abs(x[idx]-x[mid_point])]) > mp_thresh):\n",
    "                new_peak_idx.append(idx_next)\n",
    "\n",
    "        peak_idx = np.array(new_peak_idx)\n",
    "        peak_amp = x[peak_idx]\n",
    "\n",
    "    if plot == True:\n",
    "        fig, [ax1] = plt.subplots(nrows=1, ncols=1, sharex=True, figsize=(8,8))\n",
    "        ax1.plot(x, 'b' , xdn, 'r--', peak_idx, peak_amp, 'kx')\n",
    "        #plt.title(fileName)\n",
    "        ax1.set_xlabel('Sample')\n",
    "        ax1.set_ylabel('Normalised amplitude')\n",
    "        ax1.legend(['Original segment', 'Denoised segment', 'Detected peaks'])\n",
    "\n",
    "        plt.draw()\n",
    "        plt.waitforbuttonpress(0) # this will wait for indefinite time\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "    return peak_idx, peak_amp\n",
    "\n",
    "def sample_entropy(U, m, r):\n",
    "\n",
    "    def _maxdist(x_i, x_j):\n",
    "        result = max([abs(ua-va) for ua, va in zip(x_i, x_j)])\n",
    "        return result\n",
    "\n",
    "    def _phi(m):\n",
    "        x = np.zeros([N,m-1])\n",
    "        for i in range(N-m+1):\n",
    "            x[i,:] = U[i:i+m-1]\n",
    "\n",
    "        C = 0\n",
    "        for i in range(len(x)):\n",
    "            for j in range(len(x)):\n",
    "                if i != j:\n",
    "                    if _maxdist(x[i,:], x[j,:]) <= r:\n",
    "                        C = C + 1\n",
    "\n",
    "        return C\n",
    "\n",
    "    U = U/max(abs(U))\n",
    "    N = len(U)\n",
    "\n",
    "    return -np.log(_phi(m+1)/_phi(m))\n",
    "\n",
    "def percentage_fractionation(x, peak_idxs, thresh=0.01, sr=1000):\n",
    "    # Get peak indexes and amplitude\n",
    "    peak_idx_diffs = np.diff(peak_idxs)\n",
    "    frac_time = 0\n",
    "    frac_time = np.sum(peak_idx_diffs[peak_idx_diffs < thresh*sr])\n",
    "    prcnt_frac = (frac_time/len(x))*100\n",
    "    return prcnt_frac\n",
    "\n",
    "def get_local_sample_entropy(x, centre_idx, width, m=2, r=0.05):\n",
    "    # Ensure width is odd\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return sample_entropy(x[:width+1], m, r)\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return sample_entropy(x[len(x)-1-width:], m, r)\n",
    "    else:\n",
    "        return sample_entropy(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)], m, r)\n",
    "    \n",
    "def get_location_of_max_energy(x, M=14):\n",
    "    v = np.ones(M)\n",
    "    x_ = np.convolve(abs(x), v)\n",
    "    return (np.argmax(x_) + math.floor(M/2))\n",
    "        \n",
    "def get_local_peaks(x, centre_idx, width=25, height_thresh=0.1):\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return get_peaks(x[:width+1], height_thresh)\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return get_peaks(x[len(x)-1-width:], height_thresh)\n",
    "    else:\n",
    "        return get_peaks(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)], height_thresh)\n",
    "    \n",
    "def get_pse(x):\n",
    "    x_fft = np.fft.rfft(x)\n",
    "    x_P = (1/len(x_fft))*np.absolute(x_fft)**2\n",
    "    x_p = x_P/sum(x_P)\n",
    "    pse = np.sum([(-p*np.log2(p)) for p in x_p])\n",
    "    return pse\n",
    "\n",
    "def get_local_pse(x, centre_idx, width=50):\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return get_pse(x[:width+1])\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return get_pse(x[len(x)-1-width:])\n",
    "    else:\n",
    "        return get_pse(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)])\n",
    "    \n",
    "def get_spectral_centroid(x):\n",
    "    x_fft = np.fft.rfft(x)\n",
    "    x_spectrum = np.absolute(x_fft)\n",
    "    normalized_spectrum = x_spectrum/sum(x_spectrum)\n",
    "    normalized_frequencies = np.arange(0, len(x_spectrum), 1)\n",
    "    return sum(normalized_frequencies * normalized_spectrum)\n",
    "\n",
    "def get_local_spectral_centroid(x, centre_idx, width=50):\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return get_spectral_centroid(x[:width+1])\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return get_spectral_centroid(x[len(x)-1-width:])\n",
    "    else:\n",
    "        return get_spectral_centroid(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)])\n",
    "    \n",
    "def get_local_energy(x, centre_idx, width=60):\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return np.sum(x[:width+1]**2)\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return np.sum(x[len(x)-1-width:]**2)\n",
    "    else:\n",
    "        return np.sum(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)]**2)\n",
    "    \n",
    "def get_width_max_energy(x, M=14, width_thresh=0.2):\n",
    "    v = np.ones(M)\n",
    "    x_ = np.convolve(abs(x), v)\n",
    "    if any(x_[np.argmax(x_):] < width_thresh*np.max(x_)):\n",
    "        end_idx = np.argmax(x_) + np.argmax(x_[np.argmax(x_):] < width_thresh*np.max(x_))\n",
    "    else:\n",
    "        end_idx = len(x_)-1\n",
    "    if any(x_[np.argmax(x_)::-1] < width_thresh*np.max(x_)):  \n",
    "        start_idx = np.argmax(x_) - np.argmax(x_[np.argmax(x_)::-1] < width_thresh*np.max(x_))\n",
    "    else:\n",
    "        start_idx = 0\n",
    "\n",
    "    return (end_idx - start_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_dict(x, col_prefix=''):\n",
    "    feature_dict = {}\n",
    "    height_thresh=0.1\n",
    "        \n",
    "    # Hand engineered features\n",
    "    peaks = get_peaks(x, height_thresh)\n",
    "    feature_dict[col_prefix + 'Number of Peaks'] = len(peaks[0])\n",
    "    feature_dict[col_prefix + 'Percentage Fractionation'] = percentage_fractionation(x, peaks[0], thresh=0.01)\n",
    "    \n",
    "    \n",
    "    max_energy_idx = get_location_of_max_energy(x)\n",
    "    feature_dict[col_prefix + 'Location of Maximum Energy'] = max_energy_idx\n",
    "    feature_dict[col_prefix + 'Sample Entropy Around Max Energy'] = get_local_sample_entropy(x, max_energy_idx, 30, m=3, r=0.15)\n",
    "    feature_dict[col_prefix + 'Width of Maximum Energy'] = get_width_max_energy(x, M=14, width_thresh=0.2)\n",
    "    \n",
    "    # Temporal features\n",
    "    feature_dict[col_prefix + 'Ratio Above 1xSTD'] = feature_calculators.ratio_beyond_r_sigma(x, 1)\n",
    "    feature_dict[col_prefix + 'Mean Absolute Value'] = np.mean(abs(x)/max(abs(x)))\n",
    "    \n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
