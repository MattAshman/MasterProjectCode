{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/matthewashman/github/MasterProject2018')\n",
    "\n",
    "# Import necessary modules. Set settings. Import data.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "# For model building\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import preprocessing\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Miscelaneous\n",
    "from IPython.display import display, clear_output\n",
    "import pdb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "X_train = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_train.pkl')\n",
    "X_validation = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_validation.pkl')\n",
    "X_augmented_01 = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_augmented_01.pkl')\n",
    "X_augmented_02 = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_augmented_02.pkl')\n",
    "X_augmented_03 = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_augmented_03.pkl')\n",
    "X_augmented_04 = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_augmented_04.pkl')\n",
    "X_validation_augmented_03 = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_validation_augmented_03.pkl')\n",
    "X_test = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_test.pkl')\n",
    "X_test_augmented_03 = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_test_augmented_03.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making single correction to label\n",
    "correction_idx = X_test.loc[(X_test['Patient']=='14') & (X_test['Type']=='af') & (X_test['Channel']=='CS3-4') &\n",
    "                            (X_test['Coupling Interval']=='300')].index[0]\n",
    "\n",
    "X_test.at[correction_idx, 'Label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate feature matrices, target vectors and information for upsampled dataset\n",
    "X_train_ = X_train.drop(['Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1)\n",
    "y_train = X_train['Label'].astype(int)\n",
    "info_train = X_train[['Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]\n",
    "\n",
    "X_augmented_01_ = X_augmented_01.drop(['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1)\n",
    "y_augmented_01 = X_augmented_01['Label'].astype(int)\n",
    "info_augmented_01 = X_augmented_01[['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]\n",
    "\n",
    "X_augmented_02_ = X_augmented_02.drop(['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1)\n",
    "y_augmented_02 = X_augmented_02['Label'].astype(int)\n",
    "info_augmented_02 = X_augmented_02[['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]\n",
    "\n",
    "X_augmented_03_ = X_augmented_03.drop(['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1)\n",
    "y_augmented_03 = X_augmented_03['Label'].astype(int)\n",
    "info_augmented_03 = X_augmented_03[['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]\n",
    "\n",
    "X_augmented_04_ = X_augmented_04.drop(['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1)\n",
    "y_augmented_04 = X_augmented_04['Label'].astype(int)\n",
    "info_augmented_04 = X_augmented_04[['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]\n",
    "\n",
    "X_validation_ = X_validation.drop(['Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1)\n",
    "y_validation = X_validation['Label'].astype(int)\n",
    "info_validation = X_validation[['Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]\n",
    "\n",
    "X_validation_augmented_03_ = X_validation_augmented_03.drop(['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1)\n",
    "y_validation_augmented_03 = X_validation_augmented_03['Label'].astype(int)\n",
    "info_validation_augmented_03 = X_validation_augmented_03[['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]\n",
    "\n",
    "X_test_augmented_03_ = X_test_augmented_03.drop(['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1)\n",
    "y_test_augmented_03 = X_test_augmented_03['Label'].astype(int)\n",
    "info_test_augmented_03 = X_test_augmented_03[['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]\n",
    "\n",
    "X_test_ = X_test.drop(['Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1)\n",
    "y_test = X_test['Label'].astype(int)\n",
    "info_test = X_test[['Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined_augmented_03 = pd.concat([X_augmented_03_, X_validation_augmented_03_, X_test_augmented_03_], ignore_index=True)\n",
    "y_combined_augmented_03 = pd.concat([y_augmented_03, y_validation_augmented_03, y_test_augmented_03], ignore_index=True)\n",
    "info_combined_augmented_03 = pd.concat([info_augmented_03, info_validation_augmented_03, info_test_augmented_03], ignore_index=True)\n",
    "\n",
    "X_combined_ = pd.concat([X_train_, X_validation_, X_test_], ignore_index=True)\n",
    "y_combined = pd.concat([y_train, y_validation, y_test], ignore_index=True)\n",
    "info_combined = pd.concat([info_train, info_validation, info_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Model and Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l1', C=1, random_state=1, solver='saga', multi_class='multinomial', \n",
    "                         class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Feature Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug1 = X_augmented_01_.values\n",
    "X_aug2 = X_augmented_02_.values\n",
    "X_aug3 = X_augmented_03_.values\n",
    "X_aug4 = X_augmented_04_.values\n",
    "X = X_train_.values\n",
    "X_val = X_validation_.values\n",
    "X_val_aug3 = X_validation_augmented_03_.values\n",
    "X_t = X_test_.values\n",
    "X_t_aug3 = X_test_augmented_03_.values\n",
    "\n",
    "X_combined_aug3 = X_combined_augmented_03.values\n",
    "X_combined = X_combined_.values\n",
    "\n",
    "y_aug1 = y_augmented_01.values\n",
    "y_aug2 = y_augmented_02.values\n",
    "y_aug3 = y_augmented_03.values\n",
    "y_aug4 = y_augmented_04.values\n",
    "y = y_train.values\n",
    "y_val = y_validation.values\n",
    "y_val_aug3 = y_validation_augmented_03.values\n",
    "y_t = y_test.values\n",
    "y_combined_aug3 = y_combined_augmented_03.values\n",
    "y_combined = y_combined.values\n",
    "\n",
    "X_info = info_train\n",
    "X_val_info = info_validation\n",
    "X_test_info = info_test\n",
    "X_combined_info = info_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Predictions\n",
      "     t/p  Green Amber   Red \n",
      "    Green 710.0  98.0   2.0 \n",
      "    Amber  29.0  98.0  20.0 \n",
      "      Red   0.0   5.0  23.0 \n",
      "F1 Score: 0.8558177823001853\n",
      "\n",
      "Validation Data Predictions\n",
      "     t/p  Green Amber   Red \n",
      "    Green 242.0  23.0   1.0 \n",
      "    Amber   8.0  26.0   9.0 \n",
      "      Red   0.0   1.0  12.0 \n",
      "F1 Score: 0.8772086100495843\n",
      "\n",
      "Combined Data Predictions\n",
      "     t/p  Green Amber   Red \n",
      "    Green 1798.0 224.0   5.0 \n",
      "    Amber  60.0 248.0  55.0 \n",
      "      Red   0.0   8.0  66.0 \n",
      "F1 Score: 0.8679522029985935\n",
      "\n",
      "Test Data Predictions\n",
      "     t/p  Green Amber   Red \n",
      "    Green 846.0 103.0   2.0 \n",
      "    Amber  23.0 124.0  26.0 \n",
      "      Red   0.0   2.0  31.0 \n",
      "F1 Score: 0.8756110476322128\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_combined_aug3, y_combined_aug3)\n",
    "\n",
    "predictions = clf.predict(X)\n",
    "predictions_val = clf.predict(X_val)\n",
    "predictions_t = clf.predict(X_t)\n",
    "predictions_combined = clf.predict(X_combined)\n",
    "\n",
    "pp = clf.predict_proba(X)\n",
    "pp_val = clf.predict_proba(X_val)\n",
    "pp_t = clf.predict_proba(X_t)\n",
    "pp_combined = clf.predict_proba(X_combined)\n",
    "\n",
    "print('Training Data Predictions')\n",
    "cm = confusion_matrix(y, predictions)\n",
    "print_cm(cm, ['Green', 'Amber','Red'])\n",
    "f1 = f1_score(y, predictions, average='weighted')\n",
    "print('F1 Score: ' + str(f1))\n",
    "\n",
    "print('\\nValidation Data Predictions')\n",
    "cm = confusion_matrix(y_val, predictions_val)\n",
    "print_cm(cm, ['Green', 'Amber','Red'])\n",
    "f1 = f1_score(y_val, predictions_val, average='weighted')\n",
    "print('F1 Score: ' + str(f1))\n",
    "\n",
    "print('\\nCombined Data Predictions')\n",
    "cm = confusion_matrix(y_combined, predictions_combined)\n",
    "print_cm(cm, ['Green', 'Amber','Red'])\n",
    "f1 = f1_score(y_combined, predictions_combined, average='weighted')\n",
    "print('F1 Score: ' + str(f1))\n",
    "\n",
    "print('\\nTest Data Predictions')\n",
    "cm = confusion_matrix(y_t, predictions_t)\n",
    "print_cm(cm, ['Green', 'Amber','Red'])\n",
    "f1 = f1_score(y_t, predictions_t, average='weighted')\n",
    "print('F1 Score: ' + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_info['Green PP'] = pp[:,0]\n",
    "X_info['Amber PP'] = pp[:,1]\n",
    "X_info['Red PP'] = pp[:,2]\n",
    "X_info['Predicitions'] = predictions\n",
    "\n",
    "X_val_info['Green PP'] = pp_val[:,0]\n",
    "X_val_info['Amber PP'] = pp_val[:,1]\n",
    "X_val_info['Red PP'] = pp_val[:,2]\n",
    "X_val_info['Predicitions'] = predictions_val\n",
    "\n",
    "X_test_info['Green PP'] = pp_t[:,0]\n",
    "X_test_info['Amber PP'] = pp_t[:,1]\n",
    "X_test_info['Red PP'] = pp_t[:,2]\n",
    "X_test_info['Predicitions'] = predictions_t\n",
    "\n",
    "X_combined_info['Green PP'] = pp_combined[:,0]\n",
    "X_combined_info['Amber PP'] = pp_combined[:,1]\n",
    "X_combined_info['Red PP'] = pp_combined[:,2]\n",
    "X_combined_info['Predicitions'] = predictions_combined\n",
    "\n",
    "X_info['Weighted PP'] = pp[:,1] + 2*pp[:,2]\n",
    "X_val_info['Weighted PP'] = pp_val[:,1] + 2*pp_val[:,2]\n",
    "X_test_info['Weighted PP'] = pp_t[:,1] + 2*pp_t[:,2]\n",
    "X_combined_info['Weighted PP'] = pp_combined[:,1] + 2*pp_combined[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AF vs Non-AF Training Data Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "channels = X_combined['Channel'].unique()\n",
    "patient_types = X_combined['Type'].unique()\n",
    "\n",
    "for patient_type in patient_types:\n",
    "    patients = X_combined_info[X_combined_info['Type']==patient_type]['Patient'].unique()\n",
    "    for patient in patients:\n",
    "        X_patient = X_combined_info[(X_combined_info['Type']==patient_type) & (X_combined_info['Patient']==patient)]\n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(16,9))\n",
    "        for channel, ax in zip(channels, axes):\n",
    "            channel_cis = X_patient[X_patient['Channel']==channel]['Coupling Interval']\n",
    "            x = channel_cis.astype(int)\n",
    "            y = X_patient[X_patient['Channel']==channel]['Weighted PP'].values\n",
    "            \n",
    "            ax.set_title(patient_type + patient + ': ' + channel)\n",
    "            ax.set_ylabel('Weighted Prediction')\n",
    "            ax.plot(x, y)\n",
    "            ax.set_xlim(400, 220)\n",
    "            ax.set_ylim(0, 2)\n",
    "            ax.grid(True)\n",
    "        \n",
    "        ax.set_xlabel('Coupling Interval')\n",
    "        plt.draw()\n",
    "        plt.waitforbuttonpress()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AF vs non-AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "%matplotlib qt\n",
    "\n",
    "channels = X_combined_info['Channel'].unique()\n",
    "patient_types = X_combined_info['Type'].unique()\n",
    "all_cis = X_combined_info['Coupling Interval'].unique().astype(int)\n",
    "all_cis = np.sort(all_cis)[::-1]\n",
    "\n",
    "af_f_values = defaultdict(list)\n",
    "non_af_f_values = defaultdict(list)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(10,6), dpi=80)\n",
    "\n",
    "for patient_type in patient_types:\n",
    "    patients = X_combined_info[X_combined_info['Type']==patient_type]['Patient'].unique()\n",
    "    for patient in patients:\n",
    "        X_patient = X_combined_info[(X_combined_info['Type']==patient_type) & (X_combined_info['Patient']==patient)]\n",
    "        \n",
    "        if patient_type == 'af':\n",
    "            for channel, ax in zip(channels, axes[:,0]):\n",
    "                channel_cis = X_patient[X_patient['Channel']==channel]['Coupling Interval']\n",
    "                x = channel_cis.astype(int)\n",
    "                y = X_patient[X_patient['Channel']==channel]['Weighted PP'].values       \n",
    "                ax.plot(x, y, 'tab:red', alpha=0.3)\n",
    "                for i, ci in enumerate(channel_cis):\n",
    "                    af_f_values[(channel + ' ' + str(ci))].append(y[i])\n",
    "                \n",
    "        else:\n",
    "            for channel, ax in zip(channels, axes[:,1]):\n",
    "                channel_cis = X_patient[X_patient['Channel']==channel]['Coupling Interval']\n",
    "                x = channel_cis.astype(int)\n",
    "                y = X_patient[X_patient['Channel']==channel]['Weighted PP'].values\n",
    "                ax.plot(x, y, 'tab:green', alpha=0.3)\n",
    "                for i, ci in enumerate(channel_cis):\n",
    "                    non_af_f_values[(channel + ' ' + str(ci))].append(y[i])\n",
    "\n",
    "                    \n",
    "\n",
    "cs12_af_f_values = [af_f_values[('CS1-2' + ' ' + str(ci))] for ci in all_cis]\n",
    "cs34_af_f_values = [af_f_values[('CS3-4' + ' ' + str(ci))] for ci in all_cis]\n",
    "cs56_af_f_values = [af_f_values[('CS5-6' + ' ' + str(ci))] for ci in all_cis]\n",
    "\n",
    "cs12_non_af_f_values = [non_af_f_values[('CS1-2' + ' ' + str(ci))] for ci in all_cis]\n",
    "cs34_non_af_f_values = [non_af_f_values[('CS3-4' + ' ' + str(ci))] for ci in all_cis]\n",
    "cs56_non_af_f_values = [non_af_f_values[('CS5-6' + ' ' + str(ci))] for ci in all_cis]\n",
    "   \n",
    "cs12_af_f_means = [np.median(l) for l in cs12_af_f_values]\n",
    "cs34_af_f_means = [np.median(l) for l in cs34_af_f_values]\n",
    "cs56_af_f_means = [np.median(l) for l in cs56_af_f_values]\n",
    "\n",
    "cs12_non_af_f_means = [np.median(l) for l in cs12_non_af_f_values]\n",
    "cs34_non_af_f_means = [np.median(l) for l in cs34_non_af_f_values]\n",
    "cs56_non_af_f_means = [np.median(l) for l in cs56_non_af_f_values]\n",
    "\n",
    "axes[0,0].plot(all_cis[cs12_af_f_means != np.nan].reshape(19), cs12_af_f_means, 'k', linewidth=2)\n",
    "axes[1,0].plot(all_cis[cs34_af_f_means != np.nan].reshape(19), cs34_af_f_means, 'k', linewidth=2)\n",
    "axes[2,0].plot(all_cis[cs56_af_f_means != np.nan].reshape(19), cs56_af_f_means, 'k', linewidth=2)\n",
    "\n",
    "axes[0,1].plot(all_cis[cs12_non_af_f_means != np.nan].reshape(19), cs12_non_af_f_means, 'k', linewidth=2)\n",
    "axes[1,1].plot(all_cis[cs34_non_af_f_means != np.nan].reshape(19), cs34_non_af_f_means, 'k', linewidth=2)\n",
    "axes[2,1].plot(all_cis[cs56_non_af_f_means != np.nan].reshape(19), cs56_non_af_f_means, 'k', linewidth=2)\n",
    "\n",
    "\n",
    "axes[0,0].set_title('AF Patients', fontsize=14)\n",
    "axes[0,1].set_title('Non-AF Patients', fontsize=14)\n",
    "\n",
    "axes[2,0].set_xlabel('S1/S2 Interval (ms)', fontsize=12)\n",
    "axes[2,1].set_xlabel('S1/S2 Interval (ms)', fontsize=12)\n",
    "\n",
    "for channel, ax in zip(channels, axes[:,0]):\n",
    "    ax.set_ylabel((' $f_{score}$'), fontsize=12)\n",
    "    \n",
    "for i, channel in enumerate(channels):\n",
    "    for ax in axes[i,:]:\n",
    "        ax.legend([ax.lines[-1]], [(channel + ' Median')])\n",
    "#     ax.annotate(channel, xy=(50,90), xycoords='axes points',\n",
    "#             size=12, ha='right', va='top',\n",
    "#             bbox=dict(boxstyle='round', fc='w'))\n",
    "    \n",
    "#     ax.set_ylabel((' $f_{score}$'), fontsize=12)\n",
    "\n",
    "for ax in axes.ravel():\n",
    "    ax.spines[\"top\"].set_alpha(0.0)    \n",
    "    ax.spines[\"bottom\"].set_alpha(0.3)\n",
    "    ax.spines[\"right\"].set_alpha(0.0)    \n",
    "    ax.spines[\"left\"].set_alpha(0.3)\n",
    "    ax.set_xlim(400, 220)\n",
    "    ax.set_ylim(0, 2)\n",
    "    ax.grid(True)\n",
    "    ax.set_axisbelow(True)\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same Plot For Popular Feature Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "%matplotlib qt\n",
    "\n",
    "feature = 'Number of Peaks'\n",
    "\n",
    "channels = X_combined_info['Channel'].unique()\n",
    "patient_types = X_combined_info['Type'].unique()\n",
    "all_cis = X_combined_info['Coupling Interval'].unique().astype(int)\n",
    "all_cis = np.sort(all_cis)[::-1]\n",
    "\n",
    "af_feature_values = defaultdict(list)\n",
    "non_af_feature_values = defaultdict(list)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(10,6), dpi=80)\n",
    "\n",
    "for patient_type in patient_types:\n",
    "    patients = X_combined_info[X_combined_info['Type']==patient_type]['Patient'].unique()\n",
    "    for patient in patients:\n",
    "        X_patient = X_combined_info[(X_combined_info['Type']==patient_type) & (X_combined_info['Patient']==patient)]\n",
    "        X_patient_features = X_combined_[(X_combined_info['Type']==patient_type) & (X_combined_info['Patient']==patient)]\n",
    "        \n",
    "        if patient_type == 'af':\n",
    "            for channel, ax in zip(channels, axes[:,0]):\n",
    "                channel_cis = X_patient[X_patient['Channel']==channel]['Coupling Interval']\n",
    "                x = channel_cis.astype(int)\n",
    "                y = X_patient_features[X_patient['Channel']==channel][feature].values       \n",
    "                ax.plot(x, y, 'tab:red', alpha=0.3)\n",
    "                for i, ci in enumerate(channel_cis):\n",
    "                    af_feature_values[(channel + ' ' + str(ci))].append(y[i])\n",
    "                \n",
    "        else:\n",
    "            for channel, ax in zip(channels, axes[:,1]):\n",
    "                channel_cis = X_patient[X_patient['Channel']==channel]['Coupling Interval']\n",
    "                x = channel_cis.astype(int)\n",
    "                y = X_patient_features[X_patient['Channel']==channel][feature].values\n",
    "                ax.plot(x, y, 'tab:green', alpha=0.3)\n",
    "                for i, ci in enumerate(channel_cis):\n",
    "                    non_af_feature_values[(channel + ' ' + str(ci))].append(y[i])\n",
    "\n",
    "                    \n",
    "\n",
    "cs12_af_feature_values = [af_feature_values[('CS1-2' + ' ' + str(ci))] for ci in all_cis]\n",
    "cs34_af_feature_values = [af_feature_values[('CS3-4' + ' ' + str(ci))] for ci in all_cis]\n",
    "cs56_af_feature_values = [af_feature_values[('CS5-6' + ' ' + str(ci))] for ci in all_cis]\n",
    "\n",
    "cs12_non_af_feature_values = [non_af_feature_values[('CS1-2' + ' ' + str(ci))] for ci in all_cis]\n",
    "cs34_non_af_feature_values = [non_af_feature_values[('CS3-4' + ' ' + str(ci))] for ci in all_cis]\n",
    "cs56_non_af_feature_values = [non_af_feature_values[('CS5-6' + ' ' + str(ci))] for ci in all_cis]\n",
    "   \n",
    "cs12_af_f_means = [np.median(l) for l in cs12_af_feature_values]\n",
    "cs34_af_f_means = [np.median(l) for l in cs34_af_feature_values]\n",
    "cs56_af_f_means = [np.median(l) for l in cs56_af_feature_values]\n",
    "\n",
    "cs12_non_af_f_means = [np.median(l) for l in cs12_non_af_feature_values]\n",
    "cs34_non_af_f_means = [np.median(l) for l in cs34_non_af_feature_values]\n",
    "cs56_non_af_f_means = [np.median(l) for l in cs56_non_af_feature_values]\n",
    "\n",
    "axes[0,0].plot(all_cis[cs12_af_f_means != np.nan].reshape(19), cs12_af_f_means, 'k', linewidth=2)\n",
    "axes[1,0].plot(all_cis[cs34_af_f_means != np.nan].reshape(19), cs34_af_f_means, 'k', linewidth=2)\n",
    "axes[2,0].plot(all_cis[cs56_af_f_means != np.nan].reshape(19), cs56_af_f_means, 'k', linewidth=2)\n",
    "\n",
    "axes[0,1].plot(all_cis[cs12_non_af_f_means != np.nan].reshape(19), cs12_non_af_f_means, 'k', linewidth=2)\n",
    "axes[1,1].plot(all_cis[cs34_non_af_f_means != np.nan].reshape(19), cs34_non_af_f_means, 'k', linewidth=2)\n",
    "axes[2,1].plot(all_cis[cs56_non_af_f_means != np.nan].reshape(19), cs56_non_af_f_means, 'k', linewidth=2)\n",
    "\n",
    "\n",
    "axes[0,0].set_title('AF Patients', fontsize=14)\n",
    "axes[0,1].set_title('Non-AF Patients', fontsize=14)\n",
    "\n",
    "axes[2,0].set_xlabel('S1/S2 Interval (ms)', fontsize=12)\n",
    "axes[2,1].set_xlabel('S1/S2 Interval (ms)', fontsize=12)\n",
    "\n",
    "for channel, ax in zip(channels, axes[:,0]):\n",
    "    ax.set_ylabel('Number of Peaks', fontsize=10)\n",
    "    \n",
    "for i, channel in enumerate(channels):\n",
    "    for ax in axes[i,:]:\n",
    "        ax.legend([ax.lines[-1]], [(channel + ' Median')], fontsize=12, loc=2)\n",
    "#     ax.annotate(channel, xy=(50,90), xycoords='axes points',\n",
    "#             size=12, ha='right', va='top',\n",
    "#             bbox=dict(boxstyle='round', fc='w'))\n",
    "    \n",
    "#     ax.set_ylabel((' $f_{score}$'), fontsize=12)\n",
    "\n",
    "for ax in axes.ravel():\n",
    "    ax.spines[\"top\"].set_alpha(0.0)    \n",
    "    ax.spines[\"bottom\"].set_alpha(0.3)\n",
    "    ax.spines[\"right\"].set_alpha(0.0)    \n",
    "    ax.spines[\"left\"].set_alpha(0.3)\n",
    "    ax.set_xlim(400, 220)\n",
    "    ax.set_ylim(0, 10)\n",
    "    ax.grid(True)\n",
    "    ax.set_axisbelow(True)\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AF vs Non-AF Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "channels = X_test_info['Channel'].unique()\n",
    "patient_types = X_test_info['Type'].unique()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(16,9))\n",
    "\n",
    "axes[0,0].set_title('AF Patients')\n",
    "axes[0,1].set_title('Non-AF Patients')\n",
    "\n",
    "for channel, ax in zip(channels, axes[:,0]):\n",
    "    ax.set_ylabel(channel)\n",
    "    ax.set_xlim(400, 220)\n",
    "    ax.set_ylim(0, 2)\n",
    "    ax.grid(True)\n",
    "    \n",
    "for channel, ax in zip(channels, axes[:,1]):\n",
    "    ax.set_ylabel(channel)\n",
    "    ax.set_xlim(400, 220)\n",
    "    ax.set_ylim(0, 2)\n",
    "    ax.grid(True)\n",
    "    \n",
    "axes[2,0].set_xlabel('Coupling Interval')\n",
    "axes[2,1].set_xlabel('Coupling Interval')\n",
    "\n",
    "for patient_type in patient_types:\n",
    "    patients = X_test_info[X_test_info['Type']==patient_type]['Patient'].unique()\n",
    "    for patient in patients:\n",
    "        X_patient = X_test_info[(X_test_info['Type']==patient_type) & (X_test_info['Patient']==patient)]\n",
    "        \n",
    "        if patient_type == 'af':\n",
    "            for channel, ax in zip(channels, axes[:,0]):\n",
    "                channel_cis = X_patient[X_patient['Channel']==channel]['Coupling Interval'].values\n",
    "                x = channel_cis.astype(int)\n",
    "                y = X_patient[X_patient['Channel']==channel]['Weighted PP'].values       \n",
    "                ax.plot(x, y, 'C2')\n",
    "                patient_name = patient_type + patient\n",
    "                ax.annotate(patient_name, xy=[x[-1],y[-1]])\n",
    "                \n",
    "        else:\n",
    "            for channel, ax in zip(channels, axes[:,1]):\n",
    "                channel_cis = X_patient[X_patient['Channel']==channel]['Coupling Interval'].values\n",
    "                x = channel_cis.astype(int)\n",
    "                y = X_patient[X_patient['Channel']==channel]['Weighted PP'].values\n",
    "                ax.plot(x, y, 'C3')\n",
    "                patient_name = patient_type + patient\n",
    "                ax.annotate(patient_name, xy=[x[-1],y[-1]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max $f_{score}$ and Conduction Delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_ = pd.concat([X_combined_, X_test_], ignore_index=True)\n",
    "X_all_info = pd.concat([X_combined_info, X_test_info], ignore_index=True)\n",
    "X_all = pd.concat([X_all_, X_all_info], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-158-ce6af585b78e>(16)<module>()->None\n",
      "-> print('WTF')\n",
      "(Pdb) patient\n",
      "11\n",
      "(Pdb) patient_X['Weighted PP']\n",
      "476    0.000121\n",
      "477    0.033489\n",
      "478    0.068746\n",
      "479    0.000847\n",
      "480    0.127229\n",
      "481    0.140228\n",
      "482    0.000527\n",
      "483    0.100201\n",
      "484    0.145272\n",
      "485    0.001400\n",
      "486    0.348900\n",
      "487    0.156133\n",
      "488    0.000475\n",
      "489    0.198870\n",
      "490    0.206552\n",
      "491    0.000913\n",
      "492    1.087185\n",
      "493    0.222461\n",
      "494    0.000336\n",
      "495    0.094194\n",
      "496    0.152692\n",
      "497    0.253333\n",
      "498    1.712662\n",
      "499    0.180066\n",
      "500    0.001684\n",
      "501    0.757491\n",
      "502    0.180569\n",
      "Name: Weighted PP, dtype: float64\n",
      "(Pdb) patient_X[['Coupling Interval', 'Channel', 'Weighted PP']]\n",
      "    Coupling Interval Channel  Weighted PP\n",
      "476               400   CS1-2     0.000121\n",
      "477               400   CS3-4     0.033489\n",
      "478               400   CS5-6     0.068746\n",
      "479               380   CS1-2     0.000847\n",
      "480               380   CS3-4     0.127229\n",
      "481               380   CS5-6     0.140228\n",
      "482               360   CS1-2     0.000527\n",
      "483               360   CS3-4     0.100201\n",
      "484               360   CS5-6     0.145272\n",
      "485               340   CS1-2     0.001400\n",
      "486               340   CS3-4     0.348900\n",
      "487               340   CS5-6     0.156133\n",
      "488               320   CS1-2     0.000475\n",
      "489               320   CS3-4     0.198870\n",
      "490               320   CS5-6     0.206552\n",
      "491               300   CS1-2     0.000913\n",
      "492               300   CS3-4     1.087185\n",
      "493               300   CS5-6     0.222461\n",
      "494               290   CS1-2     0.000336\n",
      "495               290   CS3-4     0.094194\n",
      "496               290   CS5-6     0.152692\n",
      "497               280   CS1-2     0.253333\n",
      "498               280   CS3-4     1.712662\n",
      "499               280   CS5-6     0.180066\n",
      "500               270   CS1-2     0.001684\n",
      "501               270   CS3-4     0.757491\n",
      "502               270   CS5-6     0.180569\n"
     ]
    }
   ],
   "source": [
    "patients = {}\n",
    "patients['af'] = np.sort([np.int(x) for x in (X_all[X_all['Type']=='af']['Patient'].unique())])\n",
    "patients['at'] = np.sort([np.int(x) for x in (X_all[X_all['Type']=='at']['Patient'].unique())])\n",
    "patients['avnrt'] = np.sort([np.int(x) for x in (X_all[X_all['Type']=='avnrt']['Patient'].unique())])\n",
    "patients['avrt'] = np.sort([np.int(x) for x in (X_all[X_all['Type']=='avrt']['Patient'].unique())])\n",
    "patients['ep'] = np.sort([np.int(x) for x in (X_all[X_all['Type']=='ep']['Patient'].unique())])\n",
    "\n",
    "patient_types = ['af', 'at', 'avnrt', 'avrt', 'ep']\n",
    "\n",
    "model_scores_list = []\n",
    "for patient_type in patient_types:\n",
    "    for patient in patients[patient_type]:\n",
    "        patient_X = X_all[(X_all['Type']==patient_type) & (X_all['Patient']==str(patient))]\n",
    "        if (patient_type + str(patient))=='avnrt11':\n",
    "            pdb.set_trace()\n",
    "            print('WTF')\n",
    "            \n",
    "        max_f1 = np.max(patient_X['Weighted PP'].values)\n",
    "        max_delay = np.max(patient_X['Location of Maximum Energy'].values)\n",
    "        \n",
    "        patient_dict = {}\n",
    "        patient_dict['Type'] = patient_type.upper()\n",
    "        patient_dict['Patient'] = patient\n",
    "        patient_dict['Max F1'] = max_f1*5/2\n",
    "        patient_dict['Max Delay'] = max_delay\n",
    "        \n",
    "        model_scores_list.append(patient_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = pd.DataFrame(model_scores_list)\n",
    "# model_scores.to_csv(r'/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/model_analysis_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    \n",
    "    # Begin CHANGES\n",
    "    fst_empty_cell = (columnwidth-3)//2 * \" \" + \"t/p\" + (columnwidth-3)//2 * \" \"\n",
    "    \n",
    "    if len(fst_empty_cell) < len(empty_cell):\n",
    "        fst_empty_cell = \" \" * (len(empty_cell) - len(fst_empty_cell)) + fst_empty_cell\n",
    "    # Print header\n",
    "    print(\"    \" + fst_empty_cell, end=\" \")\n",
    "    # End CHANGES\n",
    "    \n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "        \n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
