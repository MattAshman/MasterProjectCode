{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/matthewashman/github/MasterProject2018')\n",
    "\n",
    "# Import necessary modules. Set settings. Import data.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "# For model building\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import preprocessing\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Miscelaneous\n",
    "from IPython.display import display, clear_output\n",
    "import pdb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "X_train = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_train.pkl')\n",
    "X_validation = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_validation.pkl')\n",
    "X_augmented_01 = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_augmented_01.pkl')\n",
    "X_augmented_02 = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_augmented_02.pkl')\n",
    "X_augmented_03 = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_augmented_03.pkl')\n",
    "X_augmented_04 = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_augmented_04.pkl')\n",
    "X_validation_augmented_03 = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_validation_augmented_03.pkl')\n",
    "X_test = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making single correction to label\n",
    "correction_idx = X_test.loc[(X_test['Patient']=='14') & (X_test['Type']=='af') & (X_test['Channel']=='CS3-4') &\n",
    "                            (X_test['Coupling Interval']=='300')].index[0]\n",
    "\n",
    "X_test.at[correction_idx, 'Label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate feature matrices, target vectors and information for upsampled dataset\n",
    "X_train_ = X_train.drop(['Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1)\n",
    "y_train = X_train['Label'].astype(int)\n",
    "info_train = X_train[['Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]\n",
    "\n",
    "X_augmented_01_ = X_augmented_01.drop(['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1)\n",
    "y_augmented_01 = X_augmented_01['Label'].astype(int)\n",
    "info_augmented_01 = X_augmented_01[['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]\n",
    "\n",
    "X_augmented_02_ = X_augmented_02.drop(['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1)\n",
    "y_augmented_02 = X_augmented_02['Label'].astype(int)\n",
    "info_augmented_02 = X_augmented_02[['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]\n",
    "\n",
    "X_augmented_03_ = X_augmented_03.drop(['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1)\n",
    "y_augmented_03 = X_augmented_03['Label'].astype(int)\n",
    "info_augmented_03 = X_augmented_03[['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]\n",
    "\n",
    "X_augmented_04_ = X_augmented_04.drop(['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1)\n",
    "y_augmented_04 = X_augmented_04['Label'].astype(int)\n",
    "info_augmented_04 = X_augmented_04[['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]\n",
    "\n",
    "X_validation_ = X_validation.drop(['Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1)\n",
    "y_validation = X_validation['Label'].astype(int)\n",
    "info_validation = X_validation[['Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]\n",
    "\n",
    "X_validation_augmented_03_ = X_validation_augmented_03.drop(['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1)\n",
    "y_validation_augmented_03 = X_validation_augmented_03['Label'].astype(int)\n",
    "info_validation_augmented_03 = X_validation_augmented_03[['Augmented', 'Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]\n",
    "\n",
    "X_test_ = X_test.drop(['Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2'], axis=1)\n",
    "y_test = X_test['Label'].astype(int)\n",
    "info_test = X_test[['Channel', 'Coupling Interval', 'Data', 'Label', 'Patient', 'Type', 'S1/S2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined_augmented_03 = pd.concat([X_augmented_03_, X_validation_augmented_03_], ignore_index=True)\n",
    "y_combined_augmented_03 = pd.concat([y_augmented_03, y_validation_augmented_03], ignore_index=True)\n",
    "info_combined_augmented_03 = pd.concat([info_augmented_03, info_validation_augmented_03], ignore_index=True)\n",
    "\n",
    "X_combined_ = pd.concat([X_train_, X_validation_], ignore_index=True)\n",
    "y_combined = pd.concat([y_train, y_validation], ignore_index=True)\n",
    "info_combined = pd.concat([info_train, info_validation], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Model and Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l1', C=1, random_state=1, solver='saga', multi_class='multinomial', \n",
    "                         class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Feature Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug1 = X_augmented_01_.values\n",
    "X_aug2 = X_augmented_02_.values\n",
    "X_aug3 = X_augmented_03_.values\n",
    "X_aug4 = X_augmented_04_.values\n",
    "X = X_train_.values\n",
    "X_val = X_validation_.values\n",
    "X_val_aug3 = X_validation_augmented_03.values\n",
    "X_t = X_test_.values\n",
    "X_combined_aug3 = X_combined_augmented_03.values\n",
    "X_combined = X_combined_.values\n",
    "\n",
    "y_aug1 = y_augmented_01.values\n",
    "y_aug2 = y_augmented_02.values\n",
    "y_aug3 = y_augmented_03.values\n",
    "y_aug4 = y_augmented_04.values\n",
    "y = y_train.values\n",
    "y_val = y_validation.values\n",
    "y_val_aug3 = y_validation_augmented_03.values\n",
    "y_t = y_test.values\n",
    "y_combined_aug3 = y_combined_augmented_03.values\n",
    "y_combined = y_combined.values\n",
    "\n",
    "X_info = info_train\n",
    "X_val_info = info_validation\n",
    "X_test_info = info_test\n",
    "X_combined_info = info_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Predictions\n",
      "     t/p  Green Amber   Red \n",
      "    Green 706.0 103.0   1.0 \n",
      "    Amber  24.0  98.0  25.0 \n",
      "      Red   0.0   5.0  23.0 \n",
      "F1 Score: 0.8538304507646335\n",
      "\n",
      "Validation Data Predictions\n",
      "     t/p  Green Amber   Red \n",
      "    Green 244.0  21.0   1.0 \n",
      "    Amber   4.0  31.0   8.0 \n",
      "      Red   0.0   2.0  11.0 \n",
      "F1 Score: 0.8965712727666241\n",
      "\\Test Data Predictions\n",
      "     t/p  Green Amber   Red \n",
      "    Green 820.0 129.0   2.0 \n",
      "    Amber  20.0 117.0  36.0 \n",
      "      Red   0.0   2.0  31.0 \n",
      "F1 Score: 0.8530997092868403\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_combined_aug3, y_combined_aug3)\n",
    "\n",
    "predictions = clf.predict(X)\n",
    "predictions_val = clf.predict(X_val)\n",
    "predictions_t = clf.predict(X_t)\n",
    "\n",
    "pp = clf.predict_proba(X)\n",
    "pp_val = clf.predict_proba(X_val)\n",
    "pp_t = clf.predict_proba(X_t)\n",
    "\n",
    "print('Training Data Predictions')\n",
    "cm = confusion_matrix(y, predictions)\n",
    "print_cm(cm, ['Green', 'Amber','Red'])\n",
    "f1 = f1_score(y, predictions, average='weighted')\n",
    "print('F1 Score: ' + str(f1))\n",
    "\n",
    "print('\\nValidation Data Predictions')\n",
    "cm = confusion_matrix(y_val, predictions_val)\n",
    "print_cm(cm, ['Green', 'Amber','Red'])\n",
    "f1 = f1_score(y_val, predictions_val, average='weighted')\n",
    "print('F1 Score: ' + str(f1))\n",
    "\n",
    "print('\\Test Data Predictions')\n",
    "cm = confusion_matrix(y_t, predictions_t)\n",
    "print_cm(cm, ['Green', 'Amber','Red'])\n",
    "f1 = f1_score(y_t, predictions_t, average='weighted')\n",
    "print('F1 Score: ' + str(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising Predictions using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# Setup LDA\n",
    "lda = LDA(n_components=2)\n",
    "# Get LDA principle components\n",
    "X_combined_lda = pd.DataFrame(data=lda.fit_transform(X_combined, y_combined), \n",
    "                     columns = ['principal component 1', 'principal component 2'])\n",
    "X_t_lda = pd.DataFrame(data=lda.transform(X_t), \n",
    "                     columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "X_combined_lda = pd.concat([X_combined_lda, X_combined_info], axis=1)\n",
    "X_t_lda = pd.concat([X_t_lda, X_test_info], axis=1)\n",
    "\n",
    "labels = [0, 1, 2]\n",
    "colors = ['g', 'orange', 'r']\n",
    "\n",
    "fig, [ax1, ax2] = plt.subplots(ncols=2, nrows=1, figsize=(10,4), dpi=80)\n",
    "\n",
    "for label, color in zip(labels, colors):\n",
    "    idx_to_keep = (y_combined == label)\n",
    "    ax1.scatter(X_combined_lda.loc[idx_to_keep, 'principal component 1'], \n",
    "                X_combined_lda.loc[idx_to_keep, 'principal component 2'],\n",
    "                c = color,\n",
    "                edgecolor='k',\n",
    "                s = 50,\n",
    "               alpha=0.1)\n",
    "    \n",
    "    ax2.scatter(X_combined_lda.loc[idx_to_keep, 'principal component 1'], \n",
    "                X_combined_lda.loc[idx_to_keep, 'principal component 2'],\n",
    "                c = color,\n",
    "                edgecolor='k',\n",
    "                s = 50,\n",
    "               alpha=0.1)\n",
    "    \n",
    "    idx_to_keep = (y_t == label)\n",
    "    ax1.scatter(X_t_lda.loc[idx_to_keep, 'principal component 1'], \n",
    "                X_t_lda.loc[idx_to_keep, 'principal component 2'],\n",
    "                c = color,\n",
    "                edgecolor='k',\n",
    "                s = 50)\n",
    "    \n",
    "    \n",
    "    ax2.scatter(X_t_lda.loc[idx_to_keep, 'principal component 1'], \n",
    "                X_t_lda.loc[idx_to_keep, 'principal component 2'],\n",
    "                c = color,\n",
    "                edgecolor='k',\n",
    "                s = 50,\n",
    "               alpha=0.1)\n",
    "    \n",
    "    error_idx = ((y_t == label) & (predictions_t != y_t))\n",
    "    ax2.scatter(X_t_lda.loc[error_idx, 'principal component 1'], \n",
    "                X_t_lda.loc[error_idx, 'principal component 2'],\n",
    "                c=color,\n",
    "                edgecolor='k',#[colors[x] for x in predictions_t[error_idx]],\n",
    "                s = 50)\n",
    "    \n",
    "names = []\n",
    "for i, row in X_t_lda.iterrows():\n",
    "    row_name = row['Type'] + row['Patient'] + ' ' + row['Channel'] + ' ' + row['Coupling Interval'] + ' ' + str(row['Label'])\n",
    "    names.append(row_name)\n",
    "    \n",
    "sc = ax2.scatter(X_t_lda['principal component 1'], X_t_lda['principal component 2'],\n",
    "                 alpha=0,\n",
    "                 s=50)\n",
    "        \n",
    "annot = ax2.annotate(\"\", xy=(0,0), xytext=(20,20),textcoords=\"offset points\",\n",
    "                     bbox=dict(boxstyle=\"round\", fc=\"w\"),\n",
    "                     arrowprops=dict(arrowstyle=\"->\"))\n",
    "\n",
    "annot.set_visible(False)\n",
    "\n",
    "def update_annot(ind):\n",
    "\n",
    "    pos = sc.get_offsets()[ind[\"ind\"][0]]\n",
    "    annot.xy = pos\n",
    "    text = \"{}\".format(\" \".join([names[n] for n in ind[\"ind\"]]))\n",
    "    annot.set_text(text)\n",
    "\n",
    "\n",
    "def hover(event):\n",
    "    vis = annot.get_visible()\n",
    "    if event.inaxes == ax2:\n",
    "        cont, ind = sc.contains(event)\n",
    "        if cont:\n",
    "            update_annot(ind)\n",
    "            annot.set_visible(True)\n",
    "            fig.canvas.draw_idle()\n",
    "        else:\n",
    "            if vis:\n",
    "                annot.set_visible(False)\n",
    "                fig.canvas.draw_idle()\n",
    "    \n",
    "    \n",
    "    \n",
    "                \n",
    "ax1.grid(True); ax2.grid(True)\n",
    "ax1.set_axisbelow(True)\n",
    "ax2.set_axisbelow(True)\n",
    "\n",
    "fig.canvas.mpl_connect(\"motion_notify_event\", hover)\n",
    "\n",
    "# Remove borders\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.spines[\"top\"].set_alpha(0.0)    \n",
    "    ax.spines[\"bottom\"].set_alpha(0.3)\n",
    "    ax.spines[\"right\"].set_alpha(0.0)    \n",
    "    ax.spines[\"left\"].set_alpha(0.3) \n",
    "    ax.set_xlabel('Principal Component 1')\n",
    "    ax.set_ylabel('Principal Component 2')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_info['Green PP'] = pp[:,0]\n",
    "X_info['Amber PP'] = pp[:,1]\n",
    "X_info['Red PP'] = pp[:,2]\n",
    "X_info['Predicitions'] = predictions\n",
    "\n",
    "X_val_info['Green PP'] = pp_val[:,0]\n",
    "X_val_info['Amber PP'] = pp_val[:,1]\n",
    "X_val_info['Red PP'] = pp_val[:,2]\n",
    "X_val_info['Predicitions'] = predictions_val\n",
    "\n",
    "X_test_info['Green PP'] = pp_t[:,0]\n",
    "X_test_info['Amber PP'] = pp_t[:,1]\n",
    "X_test_info['Red PP'] = pp_t[:,2]\n",
    "X_test_info['Predicitions'] = predictions_t\n",
    "\n",
    "X_info['Weighted PP'] = pp[:,1] + 2*pp[:,2]\n",
    "X_val_info['Weighted PP'] = pp_val[:,1] + 2*pp_val[:,2]\n",
    "X_test_info['Weighted PP'] = pp_t[:,1] + 2*pp_t[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate Misclassificaitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient: af14. CS1-2: 290. Prediction: 1.4903535795629554\n",
      "Patient: af14. CS1-2: 280. Prediction: 1.1625159242997127\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "red_errors = ((y_t == 2) & (predictions_t != y_t))\n",
    "red_error_idxs = [i for i, x in enumerate(red_errors) if x]\n",
    "for idx in red_error_idxs:\n",
    "    error_type = X_test_info.loc[idx]['Type']\n",
    "    error_patient = X_test_info.loc[idx]['Patient']\n",
    "    error_channel = X_test_info.loc[idx]['Channel']\n",
    "    error_cs = X_test_info.loc[idx]['Coupling Interval']\n",
    "    error_segment = X_test_info.loc[idx]['Data']\n",
    "    error_prediction = X_test_info.loc[idx]['Weighted PP']\n",
    "    \n",
    "    print('Patient: ' + error_type + error_patient + '. ' + error_channel + ': ' + error_cs + '. Prediction: ' + str(error_prediction))\n",
    "    \n",
    "    typical_segment = X_test_info[(X_test_info['Type']==error_type) &\n",
    "                                  (X_test_info['Patient']==error_patient) &\n",
    "                                  (X_test_info['Channel']==error_channel)\n",
    "                                 ].sort_values(by=['Coupling Interval'], ascending=False).iloc[0]['Data']\n",
    "    \n",
    "    fig, [ax1, ax2] = plt.subplots(nrows=2, ncols=1, figsize=(10,4), dpi=80, sharex=True, sharey=True)\n",
    "    ax1.plot(typical_segment, 'k')\n",
    "    ax2.plot(error_segment, 'k')\n",
    "    ax1.set_title('Typical Response', fontsize=14)\n",
    "    ax2.set_title('Fractionated Response', fontsize=14)\n",
    "    ax2.set_xlabel('Sample (ms)', fontsize=14)\n",
    "    ax2.set_ylabel(r'$\\mu$V', rotation=1, fontsize=14)\n",
    "    ax1.set_ylabel(r'$\\mu$V', rotation=1, fontsize=14)\n",
    "    \n",
    "    \n",
    "    # Remove borders\n",
    "    for ax in [ax1, ax2]:\n",
    "        ax.grid(True)\n",
    "        ax.spines[\"top\"].set_alpha(0.0)    \n",
    "        ax.spines[\"bottom\"].set_alpha(0.3)\n",
    "        ax.spines[\"right\"].set_alpha(0.0)    \n",
    "        ax.spines[\"left\"].set_alpha(0.3)  \n",
    "        ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.draw()\n",
    "    plt.waitforbuttonpress()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '3', '4', '6', '8', '9', '10'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_info[X_info['Type']=='af']['Patient'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AF vs Non-AF Training Data Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "channels = X_info['Channel'].unique()\n",
    "patient_types = X_info['Type'].unique()\n",
    "\n",
    "for patient_type in patient_types:\n",
    "    patients = X_info[X_info['Type']==patient_type]['Patient'].unique()\n",
    "    for patient in patients:\n",
    "        X_patient = X_info[(X_info['Type']==patient_type) & (X_info['Patient']==patient)]\n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(16,9))\n",
    "        for channel, ax in zip(channels, axes):\n",
    "            channel_cis = X_patient[X_patient['Channel']==channel]['Coupling Interval']\n",
    "            x = channel_cis.astype(int)\n",
    "            y = X_patient[X_patient['Channel']==channel]['Weighted PP'].values\n",
    "            \n",
    "            ax.set_title(patient_type + patient + ': ' + channel)\n",
    "            ax.set_ylabel('Weighted Prediction')\n",
    "            ax.plot(x, y)\n",
    "            ax.set_xlim(400, 220)\n",
    "            ax.set_ylim(0, 2)\n",
    "            ax.grid(True)\n",
    "        \n",
    "        ax.set_xlabel('Coupling Interval')\n",
    "        plt.draw()\n",
    "        plt.waitforbuttonpress()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "channels = X_info['Channel'].unique()\n",
    "patient_types = X_info['Type'].unique()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(16,9))\n",
    "\n",
    "axes[0,0].set_title('AF Patients')\n",
    "axes[0,1].set_title('Non-AF Patients')\n",
    "\n",
    "for channel, ax in zip(channels, axes[:,0]):\n",
    "    ax.set_ylabel(channel)\n",
    "    ax.set_xlim(400, 220)\n",
    "    ax.set_ylim(0, 2)\n",
    "    ax.grid(True)\n",
    "    \n",
    "for channel, ax in zip(channels, axes[:,1]):\n",
    "    ax.set_ylabel(channel)\n",
    "    ax.set_xlim(400, 220)\n",
    "    ax.set_ylim(0, 2)\n",
    "    ax.grid(True)\n",
    "    \n",
    "axes[2,0].set_xlabel('Coupling Interval')\n",
    "axes[2,1].set_xlabel('Coupling Interval')\n",
    "\n",
    "for patient_type in patient_types:\n",
    "    patients = X_info[X_info['Type']==patient_type]['Patient'].unique()\n",
    "    for patient in patients:\n",
    "        X_patient = X_info[(X_info['Type']==patient_type) & (X_info['Patient']==patient)]\n",
    "        \n",
    "        if patient_type == 'af':\n",
    "            for channel, ax in zip(channels, axes[:,0]):\n",
    "                channel_cis = X_patient[X_patient['Channel']==channel]['Coupling Interval']\n",
    "                x = channel_cis.astype(int)\n",
    "                y = X_patient[X_patient['Channel']==channel]['Weighted PP'].values       \n",
    "                ax.plot(x, y, 'C2')\n",
    "                \n",
    "        else:\n",
    "            for channel, ax in zip(channels, axes[:,1]):\n",
    "                channel_cis = X_patient[X_patient['Channel']==channel]['Coupling Interval']\n",
    "                x = channel_cis.astype(int)\n",
    "                y = X_patient[X_patient['Channel']==channel]['Weighted PP'].values\n",
    "                ax.plot(x, y, 'C3')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AF vs Non-AF Validation Data Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "channels = X_val_info['Channel'].unique()\n",
    "patient_types = X_val_info['Type'].unique()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(16,9))\n",
    "\n",
    "axes[0,0].set_title('AF Patients')\n",
    "axes[0,1].set_title('Non-AF Patients')\n",
    "\n",
    "for channel, ax in zip(channels, axes[:,0]):\n",
    "    ax.set_ylabel(channel)\n",
    "    ax.set_xlim(400, 220)\n",
    "    ax.set_ylim(0, 2)\n",
    "    ax.grid(True)\n",
    "    \n",
    "for channel, ax in zip(channels, axes[:,1]):\n",
    "    ax.set_ylabel(channel)\n",
    "    ax.set_xlim(400, 220)\n",
    "    ax.set_ylim(0, 2)\n",
    "    ax.grid(True)\n",
    "    \n",
    "axes[2,0].set_xlabel('Coupling Interval')\n",
    "axes[2,1].set_xlabel('Coupling Interval')\n",
    "\n",
    "for patient_type in patient_types:\n",
    "    patients = X_val_info[X_val_info['Type']==patient_type]['Patient'].unique()\n",
    "    for patient in patients:\n",
    "        X_patient = X_val_info[(X_val_info['Type']==patient_type) & (X_val_info['Patient']==patient)]\n",
    "        \n",
    "        if patient_type == 'af':\n",
    "            for channel, ax in zip(channels, axes[:,0]):\n",
    "                channel_cis = X_patient[X_patient['Channel']==channel]['Coupling Interval']\n",
    "                x = channel_cis.astype(int)\n",
    "                y = X_patient[X_patient['Channel']==channel]['Weighted PP'].values       \n",
    "                ax.plot(x, y, 'C2')\n",
    "                \n",
    "        else:\n",
    "            for channel, ax in zip(channels, axes[:,1]):\n",
    "                channel_cis = X_patient[X_patient['Channel']==channel]['Coupling Interval']\n",
    "                x = channel_cis.astype(int)\n",
    "                y = X_patient[X_patient['Channel']==channel]['Weighted PP'].values\n",
    "                ax.plot(x, y, 'C3')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AF vs Non-AF Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "channels = X_test_info['Channel'].unique()\n",
    "patient_types = X_test_info['Type'].unique()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(16,9))\n",
    "\n",
    "axes[0,0].set_title('AF Patients')\n",
    "axes[0,1].set_title('Non-AF Patients')\n",
    "\n",
    "for channel, ax in zip(channels, axes[:,0]):\n",
    "    ax.set_ylabel(channel)\n",
    "    ax.set_xlim(400, 220)\n",
    "    ax.set_ylim(0, 2)\n",
    "    ax.grid(True)\n",
    "    \n",
    "for channel, ax in zip(channels, axes[:,1]):\n",
    "    ax.set_ylabel(channel)\n",
    "    ax.set_xlim(400, 220)\n",
    "    ax.set_ylim(0, 2)\n",
    "    ax.grid(True)\n",
    "    \n",
    "axes[2,0].set_xlabel('Coupling Interval')\n",
    "axes[2,1].set_xlabel('Coupling Interval')\n",
    "\n",
    "for patient_type in patient_types:\n",
    "    patients = X_test_info[X_test_info['Type']==patient_type]['Patient'].unique()\n",
    "    for patient in patients:\n",
    "        X_patient = X_test_info[(X_test_info['Type']==patient_type) & (X_test_info['Patient']==patient)]\n",
    "        \n",
    "        if patient_type == 'af':\n",
    "            for channel, ax in zip(channels, axes[:,0]):\n",
    "                channel_cis = X_patient[X_patient['Channel']==channel]['Coupling Interval'].values\n",
    "                x = channel_cis.astype(int)\n",
    "                y = X_patient[X_patient['Channel']==channel]['Weighted PP'].values       \n",
    "                ax.plot(x, y, 'C2')\n",
    "                patient_name = patient_type + patient\n",
    "                ax.annotate(patient_name, xy=[x[-1],y[-1]])\n",
    "                \n",
    "        else:\n",
    "            for channel, ax in zip(channels, axes[:,1]):\n",
    "                channel_cis = X_patient[X_patient['Channel']==channel]['Coupling Interval'].values\n",
    "                x = channel_cis.astype(int)\n",
    "                y = X_patient[X_patient['Channel']==channel]['Weighted PP'].values\n",
    "                ax.plot(x, y, 'C3')\n",
    "                patient_name = patient_type + patient\n",
    "                ax.annotate(patient_name, xy=[x[-1],y[-1]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213, 20)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "best_f1 = 0\n",
    "for num_features in range(1, len(X_train.columns)):\n",
    "    selector = RFE(estimator, num_features, step=1)\n",
    "    selector = selector.fit(X_aug.values, y_aug)\n",
    "    print('\\nNum Features: ' + str(num_features))\n",
    "    features = X_train_aug.columns[selector.support_]\n",
    "    print(features)\n",
    "    \n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('Test score:')\n",
    "    clf.fit(X_aug[features].values, y_aug)\n",
    "    predictions = clf.predict(X_val_aug[features].values)\n",
    "    cm = confusion_matrix(y_val, predictions)\n",
    "    print_cm(cm, ['Green', 'Amber','Red'])\n",
    "    f1 = f1_score(y_val, predictions, average='weighted')\n",
    "    print('F1 Score: ' + str(f1))\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_features = features\n",
    "        best_f1 = f1\n",
    "        \n",
    "print(best_features)\n",
    "print(best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "best_f1 = 0\n",
    "for num_features in range(1, len(X_train_aug.columns)):\n",
    "    selector = RFE(estimator, num_features, step=1)\n",
    "    selector = selector.fit(X_train_aug.values, y_train_aug.values)\n",
    "    print('\\nNum Features: ' + str(num_features))\n",
    "    features = X_train_aug.columns[selector.support_]\n",
    "    print(features)\n",
    "    \n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('Test score:')\n",
    "    clf.fit(X_train_aug[features].values, y_train_aug.values)\n",
    "    predictions = clf.predict(X_validation[features].values)\n",
    "    cm = confusion_matrix(y_validation.values, predictions)\n",
    "    print_cm(cm, ['Green', 'Amber','Red'])\n",
    "    f1 = f1_score(y_validation.values, predictions, average='weighted')\n",
    "    print('F1 Score: ' + str(f1))\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_features = features\n",
    "        best_f1 = f1\n",
    "        \n",
    "print(best_features)\n",
    "print(best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    \n",
    "    # Begin CHANGES\n",
    "    fst_empty_cell = (columnwidth-3)//2 * \" \" + \"t/p\" + (columnwidth-3)//2 * \" \"\n",
    "    \n",
    "    if len(fst_empty_cell) < len(empty_cell):\n",
    "        fst_empty_cell = \" \" * (len(empty_cell) - len(fst_empty_cell)) + fst_empty_cell\n",
    "    # Print header\n",
    "    print(\"    \" + fst_empty_cell, end=\" \")\n",
    "    # End CHANGES\n",
    "    \n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "        \n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
