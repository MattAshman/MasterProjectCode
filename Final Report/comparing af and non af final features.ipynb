{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/matthewashman/github/MasterProject2018')\n",
    "\n",
    "# Import necessary modules. Set settings. Import data.\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.robust import mad\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "from FeatureExtraction.feature_tools import detect_peaks\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "import pdb\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "X = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/Data/extracted_segments.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_S2 = X[X['S1/S2']=='S2']\n",
    "X_S1 = X[X['S1/S2']=='S1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at only feature vectors of the response to the shortest S1/S2 interval first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "types = X_S2['Type'].unique()\n",
    "for patient_type in types:\n",
    "    patients = X_S2[X_S2['Type']==patient_type]['Patient'].unique()\n",
    "    for patient in patients:\n",
    "        patient_s2 = X_S2[(X_S2['Type']==patient_type) & (X_S2['Patient']==patient)]\n",
    "        patient_cis = patient_s2['Coupling Interval'].unique()\n",
    "        shortest_ci = np.sort(patient_cis)[0]\n",
    "        shortest_ci_s2 = patient_s2[patient_s2['Coupling Interval']==shortest_ci]\n",
    "        temp.append(shortest_ci_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Coupling Interval</th>\n",
       "      <th>Data</th>\n",
       "      <th>Patient</th>\n",
       "      <th>S1/S2</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>CS1-2</td>\n",
       "      <td>230</td>\n",
       "      <td>[-811, -639, -649, -716, -672, -732, -707, -68...</td>\n",
       "      <td>1</td>\n",
       "      <td>S2</td>\n",
       "      <td>af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>CS3-4</td>\n",
       "      <td>230</td>\n",
       "      <td>[-11, 49, 16, 45, 31, -14, -34, -48, -85, -79,...</td>\n",
       "      <td>1</td>\n",
       "      <td>S2</td>\n",
       "      <td>af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>CS5-6</td>\n",
       "      <td>230</td>\n",
       "      <td>[-181, -333, -765, -1010, -1271, -1570, -2082,...</td>\n",
       "      <td>1</td>\n",
       "      <td>S2</td>\n",
       "      <td>af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>CS1-2</td>\n",
       "      <td>250</td>\n",
       "      <td>[36, 30, 74, 208, 81, 232, 312, 314, 331, 235,...</td>\n",
       "      <td>2</td>\n",
       "      <td>S2</td>\n",
       "      <td>af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>CS3-4</td>\n",
       "      <td>250</td>\n",
       "      <td>[1453, 1119, 97, -144, -174, -30, 216, 251, 34...</td>\n",
       "      <td>2</td>\n",
       "      <td>S2</td>\n",
       "      <td>af</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Channel Coupling Interval  \\\n",
       "99    CS1-2               230   \n",
       "102   CS3-4               230   \n",
       "105   CS5-6               230   \n",
       "243   CS1-2               250   \n",
       "246   CS3-4               250   \n",
       "\n",
       "                                                  Data Patient S1/S2 Type  \n",
       "99   [-811, -639, -649, -716, -672, -732, -707, -68...       1    S2   af  \n",
       "102  [-11, 49, 16, 45, 31, -14, -34, -48, -85, -79,...       1    S2   af  \n",
       "105  [-181, -333, -765, -1010, -1271, -1570, -2082,...       1    S2   af  \n",
       "243  [36, 30, 74, 208, 81, 232, 312, 314, 331, 235,...       2    S2   af  \n",
       "246  [1453, 1119, 97, -144, -174, -30, 216, 251, 34...       2    S2   af  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_S2 = pd.concat(temp)\n",
    "shortest_S2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Extracting Features: 100.0%'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_list = []\n",
    "\n",
    "\n",
    "# Extract features\n",
    "for i, row in shortest_S2.iterrows():\n",
    "    clear_output(wait=True)\n",
    "    display('Extracting Features: ' + str(round(100*i/shortest_S2.index[-1],3)) + '%')\n",
    "\n",
    "    # Get typical response for this patient and channel\n",
    "    # Bad apples\n",
    "    if (((row['Type'] + row['Patient']) == 'af8') & (row['Channel'] == 'CS5-6')):\n",
    "        typical_response = X_S1[(X_S1['Type']==row['Type']) & \n",
    "                           (X_S1['Patient']==row['Patient']) &\n",
    "                           (X_S1['Channel']==row['Channel'])\n",
    "                           ].sort_values(by=['Coupling Interval'], ascending=False).iloc[2]\n",
    "    elif (((row['Type'] + row['Patient']) == 'at1') & (row['Channel'] == 'CS1-2')):\n",
    "        typical_response = X_S1[(X_S1['Type']==row['Type']) & \n",
    "                           (X_S1['Patient']==row['Patient']) &\n",
    "                           (X_S1['Channel']==row['Channel'])\n",
    "                           ].sort_values(by=['Coupling Interval'], ascending=False).iloc[4]\n",
    "    else:\n",
    "        typical_response = X_S1[(X_S1['Type']==row['Type']) & \n",
    "                               (X_S1['Patient']==row['Patient']) &\n",
    "                               (X_S1['Channel']==row['Channel'])\n",
    "                               ].sort_values(by=['Coupling Interval'], ascending=False).iloc[0]\n",
    "\n",
    "    # Normalise responses.\n",
    "    s2_response = row['Data']/max(abs(typical_response['Data']))\n",
    "    s1_response = typical_response['Data']/max(abs(typical_response['Data']))\n",
    "    \n",
    "    typical_feature_dict = get_good_feature_dict(s1_response)\n",
    "    feature_dict = get_good_feature_dict(s2_response)\n",
    "\n",
    "    # Normalise by subtracting 'typical' feature values\n",
    "    for k, v in feature_dict.items():\n",
    "        feature_dict[k] = v - typical_feature_dict[k]\n",
    "\n",
    "    feature_dict['DTW'] = dtw_around_main_energy(s2_response, s1_response)\n",
    "    # Fill in the other column values\n",
    "    for col, value in row.iteritems():\n",
    "        feature_dict[col] = value\n",
    "\n",
    "    feature_list.append(feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = pd.DataFrame(feature_list)\n",
    "final_features['AF'] = (final_features['Type']=='af')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approximate Entropy: m=3 r=0.7</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Conduction Delay: set_thresh=False</th>\n",
       "      <th>Coupling Interval</th>\n",
       "      <th>Data</th>\n",
       "      <th>Index Mass Quantile: q=0.6</th>\n",
       "      <th>Location of Maximum Energy: M=14</th>\n",
       "      <th>Number of Peaks: set_thresh=False</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Percentage Fractionation: thresh=0.01</th>\n",
       "      <th>Power Spectral Entropy</th>\n",
       "      <th>Ratio Beyond 1xSTD</th>\n",
       "      <th>S1/S2</th>\n",
       "      <th>Sample Entropy Around Max Energy: width=60 r=0.025</th>\n",
       "      <th>Type</th>\n",
       "      <th>Width of Maximum Energy: M=14, width_thresh=0.2</th>\n",
       "      <th>AF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.010016</td>\n",
       "      <td>CS1-2</td>\n",
       "      <td>4</td>\n",
       "      <td>230</td>\n",
       "      <td>[-811, -639, -649, -716, -672, -732, -707, -68...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>-0.120612</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>S2</td>\n",
       "      <td>-0.002441</td>\n",
       "      <td>af</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001857</td>\n",
       "      <td>CS3-4</td>\n",
       "      <td>6</td>\n",
       "      <td>230</td>\n",
       "      <td>[-11, 49, 16, 45, 31, -14, -34, -48, -85, -79,...</td>\n",
       "      <td>0.069231</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.615385</td>\n",
       "      <td>0.244815</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>S2</td>\n",
       "      <td>0.149385</td>\n",
       "      <td>af</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.208801</td>\n",
       "      <td>CS5-6</td>\n",
       "      <td>19</td>\n",
       "      <td>230</td>\n",
       "      <td>[-181, -333, -765, -1010, -1271, -1570, -2082,...</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>0.017853</td>\n",
       "      <td>0.161538</td>\n",
       "      <td>S2</td>\n",
       "      <td>0.252575</td>\n",
       "      <td>af</td>\n",
       "      <td>47</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001569</td>\n",
       "      <td>CS1-2</td>\n",
       "      <td>10</td>\n",
       "      <td>250</td>\n",
       "      <td>[36, 30, 74, 208, 81, 232, 312, 314, 331, 235,...</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.153846</td>\n",
       "      <td>-0.607676</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>S2</td>\n",
       "      <td>0.348953</td>\n",
       "      <td>af</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039725</td>\n",
       "      <td>CS3-4</td>\n",
       "      <td>13</td>\n",
       "      <td>250</td>\n",
       "      <td>[1453, 1119, 97, -144, -174, -30, 216, 251, 34...</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.102304</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>S2</td>\n",
       "      <td>0.472515</td>\n",
       "      <td>af</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Approximate Entropy: m=3 r=0.7 Channel  Conduction Delay: set_thresh=False  \\\n",
       "0                       -0.010016   CS1-2                                   4   \n",
       "1                        0.001857   CS3-4                                   6   \n",
       "2                        0.208801   CS5-6                                  19   \n",
       "3                        0.001569   CS1-2                                  10   \n",
       "4                        0.039725   CS3-4                                  13   \n",
       "\n",
       "  Coupling Interval                                               Data  \\\n",
       "0               230  [-811, -639, -649, -716, -672, -732, -707, -68...   \n",
       "1               230  [-11, 49, 16, 45, 31, -14, -34, -48, -85, -79,...   \n",
       "2               230  [-181, -333, -765, -1010, -1271, -1570, -2082,...   \n",
       "3               250  [36, 30, 74, 208, 81, 232, 312, 314, 331, 235,...   \n",
       "4               250  [1453, 1119, 97, -144, -174, -30, 216, 251, 34...   \n",
       "\n",
       "   Index Mass Quantile: q=0.6  Location of Maximum Energy: M=14  \\\n",
       "0                    0.038462                                 5   \n",
       "1                    0.069231                                 4   \n",
       "2                    0.230769                                33   \n",
       "3                    0.092308                                 5   \n",
       "4                    0.092308                                11   \n",
       "\n",
       "   Number of Peaks: set_thresh=False Patient  \\\n",
       "0                                  1       1   \n",
       "1                                  2       1   \n",
       "2                                  6       1   \n",
       "3                                  1       2   \n",
       "4                                  1       2   \n",
       "\n",
       "   Percentage Fractionation: thresh=0.01  Power Spectral Entropy  \\\n",
       "0                               1.538462               -0.120612   \n",
       "1                               4.615385                0.244815   \n",
       "2                              23.076923                0.017853   \n",
       "3                               6.153846               -0.607676   \n",
       "4                               0.000000               -0.102304   \n",
       "\n",
       "   Ratio Beyond 1xSTD S1/S2  \\\n",
       "0            0.007692    S2   \n",
       "1            0.030769    S2   \n",
       "2            0.161538    S2   \n",
       "3            0.030769    S2   \n",
       "4            0.007692    S2   \n",
       "\n",
       "   Sample Entropy Around Max Energy: width=60 r=0.025 Type  \\\n",
       "0                                          -0.002441    af   \n",
       "1                                           0.149385    af   \n",
       "2                                           0.252575    af   \n",
       "3                                           0.348953    af   \n",
       "4                                           0.472515    af   \n",
       "\n",
       "   Width of Maximum Energy: M=14, width_thresh=0.2    AF  \n",
       "0                                               10  True  \n",
       "1                                                2  True  \n",
       "2                                               47  True  \n",
       "3                                                7  True  \n",
       "4                                                0  True  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "%matplotlib qt\n",
    "feature_names = final_features.drop(['Patient', 'Type', 'Channel', 'AF', 'S1/S2', 'Coupling Interval', 'Data'], axis=1).columns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "# Make plot for each feature\n",
    "fig, axes = plt.subplots(ncols=2, nrows=math.ceil(len(feature_names)/2), figsize=(16,9))\n",
    "plt.rcParams.update({'font.size': 6})\n",
    "for i,feature in enumerate(feature_names):\n",
    "    if (i < math.ceil(len(feature_names)/2)):\n",
    "        axes[i,0] = sns.violinplot(x='Channel', y=feature, hue='AF', split=True, palette='Set2', data=final_features, ax=axes[i,0])\n",
    "        feature_ylabel = re.sub(r'(:)', r'\\1\\n', feature)\n",
    "        axes[i,0].set_ylabel(ylabel=feature_ylabel, fontsize=8)\n",
    "        axes[i,0].set(xlabel='')\n",
    "    else:\n",
    "        j = i - math.ceil(len(feature_names)/2)\n",
    "        axes[j,1] = sns.violinplot(x='Channel', y=feature, hue='AF', split=True, palette='Set2', data=final_features, ax=axes[j,1])\n",
    "        feature_ylabel = re.sub(r'(:)', r'\\1\\n', feature)\n",
    "        axes[j,1].set_ylabel(ylabel=feature_ylabel, fontsize=8)\n",
    "        axes[j,1].set(xlabel='')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A shitty conduction delay detector\n",
    "def get_delay(x, amp_thresh=None, set_thresh=False):\n",
    "    if (set_thresh==True):\n",
    "        if any(abs(x)>amp_thresh):\n",
    "            return np.argmax(abs(x)>amp_thresh)\n",
    "        else:\n",
    "            return len(x)\n",
    "    else:    \n",
    "        return np.argmax(abs(x)>(max(abs(x))/2))\n",
    "    \n",
    "def denoise(x):\n",
    "    # Obtain Daubechies N=6 wavelet coefficients\n",
    "    waveletCoefs = pywt.wavedec(x, 'db7', mode='per')\n",
    "\n",
    "    # Throw away coefficients corresponding to noise\n",
    "    sigma = mad(waveletCoefs[-1])\n",
    "    uThresh = 1*sigma*np.sqrt(2*np.log(len(x)))\n",
    "    denoised = waveletCoefs[:]\n",
    "    denoised[1:] = (pywt._thresholding.hard(i, value=uThresh) for i in denoised[1:])\n",
    "\n",
    "    # Reconstruct the original signal\n",
    "    xDenoised = pywt.waverec(denoised, 'db7', mode='per')\n",
    "\n",
    "    return xDenoised\n",
    "\n",
    "def get_peaks(x, height_thresh, scale_amp=None, set_scale=False, plot = False):\n",
    "    x = np.array(x)\n",
    "    \n",
    "    # Get height_thresh\n",
    "    if set_scale:\n",
    "        height_thresh = height_thresh*scale_amp\n",
    "    else:\n",
    "        height_thresh = height_thresh*max(abs(x))\n",
    "    \n",
    "    # Denoise x\n",
    "    xdn = denoise(x)\n",
    "\n",
    "    # Detect peaks using detect_peaks\n",
    "    pos_peak_idx = detect_peaks(xdn, mph=height_thresh, threshold = 0)\n",
    "    neg_peak_idx = detect_peaks((-xdn), mph=height_thresh, threshold = 0)\n",
    "    peak_idx = np.concatenate([pos_peak_idx, neg_peak_idx])\n",
    "    peak_idx = np.sort(peak_idx)\n",
    "    # Edge indeces aren't detected\n",
    "    peak_idx = peak_idx[(peak_idx != 0) & (peak_idx != (len(xdn)-1))]\n",
    "\n",
    "    new_peak_idx = []\n",
    "    peak_amp = []\n",
    "    if (len(peak_idx) > 0):\n",
    "        new_peak_idx.append(peak_idx[0])\n",
    "        mp_thresh = 0.2*max(abs(x))\n",
    "        for i in range(len(peak_idx)-1):\n",
    "            idx = peak_idx[i]\n",
    "            idx_next = peak_idx[i+1]\n",
    "            mid_point = int((idx_next+idx)/2)\n",
    "            if (max([abs(x[idx_next]-x[mid_point]), abs(x[idx]-x[mid_point])]) > mp_thresh):\n",
    "                new_peak_idx.append(idx_next)\n",
    "\n",
    "        peak_idx = np.array(new_peak_idx)\n",
    "        peak_amp = x[peak_idx]\n",
    "\n",
    "    if plot == True:\n",
    "        fig, [ax1] = plt.subplots(nrows=1, ncols=1, sharex=True, figsize=(8,8))\n",
    "        ax1.plot(x, 'b' , xdn, 'r--', peak_idx, peak_amp, 'kx')\n",
    "        #plt.title(fileName)\n",
    "        ax1.set_xlabel('Sample')\n",
    "        ax1.set_ylabel('Normalised amplitude')\n",
    "        ax1.legend(['Original segment', 'Denoised segment', 'Detected peaks'])\n",
    "\n",
    "        plt.draw()\n",
    "        plt.waitforbuttonpress(0) # this will wait for indefinite time\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "    return peak_idx, peak_amp\n",
    "\n",
    "def sample_entropy(U, m, r):\n",
    "\n",
    "    def _maxdist(x_i, x_j):\n",
    "        result = max([abs(ua-va) for ua, va in zip(x_i, x_j)])\n",
    "        return result\n",
    "\n",
    "    def _phi(m):\n",
    "        x = np.zeros([N,m-1])\n",
    "        for i in range(N-m+1):\n",
    "            x[i,:] = U[i:i+m-1]\n",
    "\n",
    "        C = 0\n",
    "        for i in range(len(x)):\n",
    "            for j in range(len(x)):\n",
    "                if i != j:\n",
    "                    if _maxdist(x[i,:], x[j,:]) <= r:\n",
    "                        C = C + 1\n",
    "\n",
    "        return C\n",
    "\n",
    "    U = U/max(abs(U))\n",
    "    N = len(U)\n",
    "\n",
    "    return -np.log(_phi(m+1)/_phi(m))\n",
    "\n",
    "def percentage_fractionation(x, peak_idxs, thresh=0.01, sr=1000):\n",
    "    # Get peak indexes and amplitude\n",
    "    peak_idx_diffs = np.diff(peak_idxs)\n",
    "    frac_time = 0\n",
    "    frac_time = np.sum(peak_idx_diffs[peak_idx_diffs < thresh*sr])\n",
    "    prcnt_frac = (frac_time/len(x))*100\n",
    "    return prcnt_frac\n",
    "\n",
    "def get_local_sample_entropy(x, centre_idx, width, m=2, r=0.05):\n",
    "    # Ensure width is odd\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return sample_entropy(x[:width+1], m, r)\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return sample_entropy(x[len(x)-1-width:], m, r)\n",
    "    else:\n",
    "        return sample_entropy(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)], m, r)\n",
    "    \n",
    "def get_location_of_max_energy(x, M=14):\n",
    "    v = np.ones(M)\n",
    "    x_ = np.convolve(abs(x), v)\n",
    "    return (np.argmax(x_) + math.floor(M/2))\n",
    "        \n",
    "def get_local_peaks(x, centre_idx, width=25, height_thresh=0.1):\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return get_peaks(x[:width+1], height_thresh)\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return get_peaks(x[len(x)-1-width:], height_thresh)\n",
    "    else:\n",
    "        return get_peaks(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)], height_thresh)\n",
    "    \n",
    "def get_pse(x):\n",
    "    x_fft = np.fft.rfft(x)\n",
    "    x_P = (1/len(x_fft))*np.absolute(x_fft)**2\n",
    "    x_p = x_P/sum(x_P)\n",
    "    pse = np.sum([(-p*np.log2(p)) for p in x_p])\n",
    "    if pse == np.nan:\n",
    "        pdb.set_trace()\n",
    "        print('WTF')\n",
    "    return pse\n",
    "\n",
    "def get_local_pse(x, centre_idx, width=50):\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return get_pse(x[:width+1])\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return get_pse(x[len(x)-1-width:])\n",
    "    else:\n",
    "        return get_pse(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)])\n",
    "    \n",
    "def get_spectral_centroid(x):\n",
    "    x_fft = np.fft.rfft(x)\n",
    "    x_spectrum = np.absolute(x_fft)\n",
    "    normalized_spectrum = x_spectrum/sum(x_spectrum)\n",
    "    normalized_frequencies = np.arange(0, len(x_spectrum), 1)\n",
    "    return sum(normalized_frequencies * normalized_spectrum)\n",
    "\n",
    "def get_local_spectral_centroid(x, centre_idx, width=50):\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return get_spectral_centroid(x[:width+1])\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return get_spectral_centroid(x[len(x)-1-width:])\n",
    "    else:\n",
    "        return get_spectral_centroid(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)])\n",
    "    \n",
    "def get_local_energy(x, centre_idx, width=60):\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return np.sum(x[:width+1]**2)\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return np.sum(x[len(x)-1-width:]**2)\n",
    "    else:\n",
    "        return np.sum(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)]**2)\n",
    "    \n",
    "def get_width_max_energy(x, M=14, width_thresh=0.2):\n",
    "    v = np.ones(M)\n",
    "    x_ = np.convolve(abs(x), v)\n",
    "    if any(x_[np.argmax(x_):] < width_thresh*np.max(x_)):\n",
    "        end_idx = np.argmax(x_) + np.argmax(x_[np.argmax(x_):] < width_thresh*np.max(x_))\n",
    "    else:\n",
    "        end_idx = len(x_)-1\n",
    "    if any(x_[np.argmax(x_)::-1] < width_thresh*np.max(x_)):  \n",
    "        start_idx = np.argmax(x_) - np.argmax(x_[np.argmax(x_)::-1] < width_thresh*np.max(x_))\n",
    "    else:\n",
    "        start_idx = 0\n",
    "    return (end_idx - start_idx)\n",
    "\n",
    "def dtw_around_main_energy(s2, s1, width=12):\n",
    "    s1_me = get_location_of_max_energy(s1)\n",
    "    s2_me = get_location_of_max_energy(s2)\n",
    "    \n",
    "    if s1_me < width:\n",
    "        s1_seg = s1[:(2*width+1)]\n",
    "    else:\n",
    "        s1_seg = s1[(s1_me-width):(s1_me+width)]\n",
    "    \n",
    "    if s2_me < width:\n",
    "        s2_seg = s2[:(2*width+1)]\n",
    "    else:\n",
    "        s2_seg = s2[(s2_me-width):(s2_me+width)]\n",
    "        \n",
    "    fdtw = fastdtw.dtw(s2_seg, s1_seg)\n",
    "    \n",
    "    return fd\n",
    "    s1_ = np.convolve(abs(s1), v)\n",
    "    if any(s1_[np.argmax(s1_):] < width_thresh*np.max(s1_)):\n",
    "        end_idx = np.argmax(s1_) + np.argmax(s1_[np.argmax(s1_):] < width_thresh*np.max(s1_))\n",
    "    else:\n",
    "        end_idx = len(s1_)-1\n",
    "    if any(s1_[np.argmax(s1_)::-1] < width_thresh*np.max(s1_)):  \n",
    "        start_idx = np.argmax(s1_) - np.argmax(s1_[np.argmax(s1_)::-1] < width_thresh*np.max(s1_))\n",
    "    else:\n",
    "        start_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_good_feature_dict(x, col_prefix=''):\n",
    "    feature_dict = {}\n",
    "    height_thresh=0.2\n",
    "    \n",
    "#     feature_dict[col_prefix + 'Maximum Absolute Value'] = max(abs(x))\n",
    "    \n",
    "    # Hand engineered features\n",
    "#     x = x/max(abs(x))\n",
    "    feature_dict[col_prefix + 'Conduction Delay: set_thresh=False'] = get_delay(x)\n",
    "    peaks = get_peaks(x, height_thresh)\n",
    "    feature_dict[col_prefix + 'Number of Peaks: set_thresh=False'] = len(peaks[0])\n",
    "    feature_dict[col_prefix + 'Percentage Fractionation: thresh=0.01'] = percentage_fractionation(x, peaks[0], thresh=0.01)\n",
    "    \n",
    "    # Denoise x for remaining features\n",
    "    x = denoise(x)\n",
    "    max_energy_idx = get_location_of_max_energy(x)\n",
    "    feature_dict[col_prefix + 'Location of Maximum Energy: M=14'] = max_energy_idx\n",
    "    feature_dict[col_prefix + 'Sample Entropy Around Max Energy: width=60 r=0.025'] = get_local_sample_entropy(x, max_energy_idx, 60, m=2, r=0.025)\n",
    "    feature_dict[col_prefix + 'Width of Maximum Energy: M=14, width_thresh=0.2'] = get_width_max_energy(x, M=14, width_thresh=0.2)\n",
    "    \n",
    "    # Temporal features\n",
    "    feature_dict[col_prefix + 'Approximate Entropy: m=3 r=0.7'] = feature_calculators.approximate_entropy(x, 3, 0.7)\n",
    "    imq = feature_calculators.index_mass_quantile(x, [{'q': 0.6}])\n",
    "    feature_dict[col_prefix + 'Index Mass Quantile: q=0.6'] = imq[0][1]\n",
    "    feature_dict[col_prefix + 'Ratio Beyond 1xSTD'] = feature_calculators.ratio_beyond_r_sigma(x, 1)\n",
    "    \n",
    "    # Spectral features\n",
    "    feature_dict[col_prefix + 'Power Spectral Entropy'] = get_pse(x)\n",
    "    \n",
    "    return feature_dict\n",
    "    \n",
    "\n",
    "def get_hand_engineered_feature_dict(x, thresh_cd=None, set_thresh_cd=False, thresh_peaks=None, set_thresh_peaks=False, show_peaks=False, col_prefix = ''):\n",
    "    feature_dict = {}\n",
    "    sf = max(abs(x))\n",
    "    x = x/max(abs(x))\n",
    "\n",
    "    # Hand engineered features\n",
    "    if set_thresh_cd:\n",
    "        thresh_cd = thresh_cd/sf\n",
    "        feature_dict[col_prefix + 'Conduction Delay: set_thresh=True'] = get_delay(x, thresh_cd, set_thresh_cd)\n",
    "        feature_dict[col_prefix + 'Conduction Delay: set_thresh=False'] = get_delay(x)\n",
    "    else:\n",
    "        feature_dict[col_prefix + 'Conduction Delay: set_thresh=False'] = get_delay(x)\n",
    "    \n",
    "    height_thresh=0.1\n",
    "    if set_thresh_peaks:\n",
    "        thresh_peaks = thresh_peaks/sf\n",
    "        peaks = get_peaks(x, height_thresh, thresh_peaks, set_thresh_peaks, plot=False)\n",
    "        feature_dict[col_prefix + 'Number of Peaks: set_thresh=True'] = len(peaks[0])\n",
    "        peaks = get_peaks(x, height_thresh)\n",
    "        feature_dict[col_prefix + 'Number of Peaks: set_thresh=False'] = len(peaks[0])\n",
    "    else:\n",
    "        peaks = get_peaks(x, height_thresh)\n",
    "        feature_dict[col_prefix + 'Number of Peaks: set_thresh=False'] = len(peaks[0])\n",
    "    \n",
    "    peaks = get_peaks(x, height_thresh)\n",
    "    feature_dict[col_prefix + 'Percentage Fractionation: thresh=0.01'] = percentage_fractionation(x, peaks[0], thresh=0.01)\n",
    "    \n",
    "    # Denoise x for remaining features\n",
    "    x = denoise(x)\n",
    "    \n",
    "    max_energy_idx = get_location_of_max_energy(x)\n",
    "    feature_dict[col_prefix + 'Location of Maximum Energy: M=14'] = max_energy_idx\n",
    "    feature_dict[col_prefix + 'Sample Entropy Around Max Energy: width=60 r=0.025'] = get_local_sample_entropy(x, max_energy_idx, 60, m=2, r=0.025)\n",
    "    feature_dict[col_prefix + 'Energy Around Max Energy'] = get_local_energy(x, max_energy_idx, 60)\n",
    "    min_idx = np.argmin(x)\n",
    "    max_idx = np.argmax(x)\n",
    "    feature_dict[col_prefix + 'Peaks Between Min and Max'] = len([i for i in peaks[0] if ((i > min_idx) & (i < max_idx))])\n",
    "    feature_dict[col_prefix + 'Width of Maximum Energy: M=14, width_thresh=0.4'] = get_width_max_energy(x, M=14, width_thresh=0.4)\n",
    "    feature_dict[col_prefix + 'Width of Maximum Energy: M=14, width_thresh=0.2'] = get_width_max_energy(x, M=14, width_thresh=0.2)\n",
    "\n",
    "    return feature_dict\n",
    "\n",
    "def get_spectral_feature_dict(x, col_prefix = ''):\n",
    "    feature_dict = {}\n",
    "    # Denoise and normalise x for remaining features\n",
    "    x = denoise(x)\n",
    "    x = x/max(abs(x))\n",
    "    \n",
    "    feature_dict[col_prefix + 'Power Spectral Entropy'] = get_pse(x)\n",
    "    feature_dict[col_prefix + 'Spectral Centroid'] = get_spectral_centroid(x)\n",
    "    max_energy_idx = get_location_of_max_energy(x)\n",
    "    feature_dict[col_prefix + 'Power Spectral Entropy Around Maximum Energy: width=30'] = get_local_pse(x, max_energy_idx, width=30)\n",
    "    feature_dict[col_prefix + 'Spectral Centroid Around Maximum Energy: width=30'] = get_local_spectral_centroid(x, max_energy_idx, width=30)\n",
    "    feature_dict[col_prefix + 'Power Spectral Entropy Around Maximum Energy: width=60'] = get_local_pse(x, max_energy_idx, width=60)\n",
    "    feature_dict[col_prefix + 'Spectral Centroid Around Maximum Energy: width=60'] = get_local_spectral_centroid(x, max_energy_idx, width=60)\n",
    "    \n",
    "    return feature_dict\n",
    "    \n",
    "def get_temporal_feature_dict(x, col_prefix = ''):\n",
    "\n",
    "    feature_dict = {}\n",
    "    feature_dict[col_prefix + 'Maximum Absolute Value'] = np.max(abs(x))\n",
    "    \n",
    "    # Denoise and normalise x for remaining features\n",
    "    x = denoise(x)\n",
    "    x = x/max(abs(x))\n",
    "\n",
    "\n",
    "    erbc = feature_calculators.energy_ratio_by_chunks(x, [{'num_segments':10, 'segment_focus':3}, {'num_segments':10, 'segment_focus':2}])\n",
    "    feature_dict[col_prefix + 'Energy Ratio by Chunks: num_segments=10 segment_focus=2'] = erbc[1][1]\n",
    "    feature_dict[col_prefix + 'Energy Ratio by Chunks: num_segments=10 segment_focus=3'] = erbc[0][1]\n",
    "    feature_dict[col_prefix + 'Approximate Entropy: m=3 r=0.7'] = feature_calculators.approximate_entropy(x, 3, 0.7)\n",
    "    feature_dict[col_prefix + 'Ratio Beyond 5xSTD'] = feature_calculators.ratio_beyond_r_sigma(x, 5)\n",
    "    feature_dict[col_prefix + 'Ratio Beyond 4xSTD'] = feature_calculators.ratio_beyond_r_sigma(x, 4)\n",
    "    feature_dict[col_prefix + 'Ratio Beyond 3xSTD'] = feature_calculators.ratio_beyond_r_sigma(x, 3)\n",
    "    feature_dict[col_prefix + 'Ratio Beyond 2xSTD'] = feature_calculators.ratio_beyond_r_sigma(x, 2)\n",
    "    feature_dict[col_prefix + 'Ratio Beyond 1xSTD'] = feature_calculators.ratio_beyond_r_sigma(x, 1)\n",
    "    # A fraction q of the mass lies to the left of i. (Alternative to conduction delay?)\n",
    "    imq = feature_calculators.index_mass_quantile(x, [{'q': 0.6}, {'q': 0.4}])\n",
    "    feature_dict[col_prefix + 'Index Mass Quantile: q=0.6'] = imq[0][1]\n",
    "    feature_dict[col_prefix + 'Index Mass Quantile: q=0.4'] = imq[1][1]\n",
    "    \n",
    "\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
