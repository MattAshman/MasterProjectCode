{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/matthewashman/github/MasterProject2018')\n",
    "\n",
    "# Import necessary modules. Set settings. Import data.\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pywt\n",
    "import fastdtw\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.robust import mad\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "from FeatureExtraction.feature_tools import detect_peaks\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import re\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import pdb\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "X = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/EPDataAnalysis/Final Report/extracted_segments_with_labels_updated.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove bad labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', nan, '1', '2', '-1'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_S1 = X[X['S1/S2']=='S1']\n",
    "X_S2 = X[X['S1/S2']=='S2']\n",
    "X_S2 = X_S2[(X_S2['Label']=='0') |(X_S2['Label']=='1') | (X_S2['Label']=='2')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Three Groups of Features From Each Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Extracting Features: 100.0%'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temporal_feature_list = []\n",
    "spectral_feature_list = []\n",
    "hand_engineered_feature_list = []\n",
    "\n",
    "temporal_feature_list_nonorm = []\n",
    "spectral_feature_list_nonorm = []\n",
    "hand_engineered_feature_list_nonorm = []\n",
    "\n",
    "for i,row in X_S2.iterrows():\n",
    "    clear_output(wait=True)\n",
    "    display('Extracting Features: ' + str(round((i/X_S2.index[-1])*100, 3)) + '%')\n",
    "    \n",
    "    # Get the patients response to the first S1 stimuli as the reference response\n",
    "    # Get typical response for this patient and channel\n",
    "    # Bad apples\n",
    "    if (((row['Type'] + row['Patient']) == 'af8') & (row['Channel'] == 'CS5-6')):\n",
    "        typical_response = X_S1[(X_S1['Type']==row['Type']) & \n",
    "                           (X_S1['Patient']==row['Patient']) &\n",
    "                           (X_S1['Channel']==row['Channel'])\n",
    "                           ].sort_values(by=['Coupling Interval'], ascending=False).iloc[2]\n",
    "    elif (((row['Type'] + row['Patient']) == 'at1') & (row['Channel'] == 'CS1-2')):\n",
    "        typical_response = X_S1[(X_S1['Type']==row['Type']) & \n",
    "                           (X_S1['Patient']==row['Patient']) &\n",
    "                           (X_S1['Channel']==row['Channel'])\n",
    "                           ].sort_values(by=['Coupling Interval'], ascending=False).iloc[4]\n",
    "    elif (((row['Type'] + row['Patient']) == 'avnrt10') & (row['Channel'] == 'CS1-2')):\n",
    "        typical_response = X_S1[(X_S1['Type']==row['Type']) & \n",
    "                           (X_S1['Patient']==row['Patient']) &\n",
    "                           (X_S1['Channel']==row['Channel'])\n",
    "                           ].sort_values(by=['Coupling Interval'], ascending=False).iloc[1]\n",
    "    elif (((row['Type'] + row['Patient']) == 'avrt13') & (row['Channel'] == 'CS1-2')):\n",
    "        typical_response = X_S2[(X_S2['Type']==row['Type']) & \n",
    "                           (X_S2['Patient']==row['Patient']) &\n",
    "                           (X_S2['Channel']==row['Channel'])\n",
    "                           ].sort_values(by=['Coupling Interval'], ascending=False).iloc[0]\n",
    "    elif (((row['Type'] + row['Patient']) == 'af14') & (row['Channel'] == 'CS1-2')):\n",
    "        typical_response = X_S2[(X_S2['Type']==row['Type']) & \n",
    "                           (X_S2['Patient']==row['Patient']) &\n",
    "                           (X_S2['Channel']==row['Channel'])\n",
    "                           ].sort_values(by=['Coupling Interval'], ascending=False).iloc[0]\n",
    "    else:\n",
    "        typical_response = X_S1[(X_S1['Type']==row['Type']) & \n",
    "                               (X_S1['Patient']==row['Patient']) &\n",
    "                               (X_S1['Channel']==row['Channel'])\n",
    "                               ].sort_values(by=['Coupling Interval'], ascending=False).iloc[0]\n",
    "        \n",
    "    # Normalise amplitudes with respect to the typical response amplitude.\n",
    "    s1_response = typical_response['Data']/max(abs(typical_response['Data']))\n",
    "    s2_response = row['Data']/max(abs(typical_response['Data']))\n",
    "        \n",
    "    ref_temporal_feature_dict = get_temporal_feature_dict(s1_response, col_prefix = '')\n",
    "    ref_spectral_feature_dict = get_spectral_feature_dict(s1_response, col_prefix = '')\n",
    "    ref_hand_engineered_feature_dict = get_hand_engineered_feature_dict(s1_response, col_prefix = '')\n",
    "    \n",
    "    temporal_feature_dict = get_temporal_feature_dict(s2_response, col_prefix = '')\n",
    "    spectral_feature_dict = get_spectral_feature_dict(s2_response, col_prefix = '')\n",
    "    hand_engineered_feature_dict = get_hand_engineered_feature_dict(s2_response, col_prefix = '')\n",
    "    \n",
    "    temporal_feature_dict_nonorm = temporal_feature_dict.copy()\n",
    "    spectral_feature_dict_nonorm = spectral_feature_dict.copy()\n",
    "    hand_engineered_feature_dict_nonorm = hand_engineered_feature_dict.copy()\n",
    "\n",
    "    \n",
    "    for (k_t, v_t), (k_s, v_s), (k_he, v_he) in zip(temporal_feature_dict.items(), spectral_feature_dict.items(), hand_engineered_feature_dict.items()):\n",
    "        temporal_feature_dict[k_t] = v_t - ref_temporal_feature_dict[k_t]\n",
    "        spectral_feature_dict[k_s] = v_s - ref_spectral_feature_dict[k_s]\n",
    "        hand_engineered_feature_dict[k_he] = v_he - ref_hand_engineered_feature_dict[k_he]\n",
    "        \n",
    "    temporal_feature_dict['Label'] = row['Label']\n",
    "    temporal_feature_dict['Channel'] = row['Channel']\n",
    "    spectral_feature_dict['Label'] = row['Label']\n",
    "    spectral_feature_dict['Channel'] = row['Channel']\n",
    "    hand_engineered_feature_dict['Label'] = row['Label']\n",
    "    hand_engineered_feature_dict['Channel'] = row['Channel']\n",
    "    \n",
    "    temporal_feature_dict_nonorm['Label'] = row['Label']\n",
    "    temporal_feature_dict_nonorm['Channel'] = row['Channel']\n",
    "    spectral_feature_dict_nonorm['Label'] = row['Label']\n",
    "    spectral_feature_dict_nonorm['Channel'] = row['Channel']\n",
    "    hand_engineered_feature_dict_nonorm['Label'] = row['Label']\n",
    "    hand_engineered_feature_dict_nonorm['Channel'] = row['Channel']\n",
    "    \n",
    "    temporal_feature_list.append(temporal_feature_dict)\n",
    "    spectral_feature_list.append(spectral_feature_dict)\n",
    "    hand_engineered_feature_list.append(hand_engineered_feature_dict)\n",
    "    \n",
    "    temporal_feature_list_nonorm.append(temporal_feature_dict_nonorm)\n",
    "    spectral_feature_list_nonorm.append(spectral_feature_dict_nonorm)\n",
    "    hand_engineered_feature_list_nonorm.append(hand_engineered_feature_dict_nonorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_features = pd.DataFrame(temporal_feature_list)\n",
    "spectral_features = pd.DataFrame(spectral_feature_list)\n",
    "hand_engineered_features = pd.DataFrame(hand_engineered_feature_list)\n",
    "\n",
    "temporal_features_nonorm = pd.DataFrame(temporal_feature_list_nonorm)\n",
    "spectral_features_nonorm = pd.DataFrame(spectral_feature_list_nonorm)\n",
    "hand_engineered_features_nonorm = pd.DataFrame(hand_engineered_feature_list_nonorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Label</th>\n",
       "      <th>Maximum Absolute Value</th>\n",
       "      <th>Ratio Beyond 1xSTD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CS1-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.338288</td>\n",
       "      <td>0.107692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CS3-4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.510449</td>\n",
       "      <td>0.092308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CS5-6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.449142</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CS1-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.340258</td>\n",
       "      <td>0.107692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CS3-4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.568009</td>\n",
       "      <td>0.092308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Channel Label  Maximum Absolute Value  Ratio Beyond 1xSTD\n",
       "0   CS1-2     0                1.338288            0.107692\n",
       "1   CS3-4     0                1.510449            0.092308\n",
       "2   CS5-6     0                1.449142            0.100000\n",
       "3   CS1-2     0                1.340258            0.107692\n",
       "4   CS3-4     0                1.568009            0.092308"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_features_nonorm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Variations in Feature Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "feature_names = temporal_features.drop(['Channel', 'Label'], axis=1).columns.tolist()\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "# Make plot for each feature\n",
    "fig, axes = plt.subplots(ncols=2, nrows=len(feature_names), figsize=(16,9))\n",
    "plt.rcParams.update({'font.size': 6})\n",
    "for i,feature in enumerate(feature_names):\n",
    "    axes[i,0] = sns.boxplot(x='Label', y=feature, palette='Set2', data=temporal_features, ax=axes[i,0])\n",
    "    feature_ylabel = re.sub(r'(:)', r'\\1\\n', feature)\n",
    "    axes[i,0].set_ylabel(ylabel=feature_ylabel, fontsize=8)\n",
    "    axes[i,0].set(xlabel='')\n",
    "    for p in (0, 1, 2):\n",
    "        y = temporal_features[temporal_features['Label']==str(p)][feature].dropna()\n",
    "        x = np.random.normal(p, 0.04, size=len(y))\n",
    "        axes[i,0].plot(x, y, 'r.', alpha=0.2)\n",
    "    \n",
    "    axes[i,1] = sns.boxplot(x='Label', y=feature, palette='Set2', data=temporal_features_nonorm, ax=axes[i,1])\n",
    "    feature_ylabel = re.sub(r'(:)', r'\\1\\n', feature)\n",
    "    axes[i,1].set_ylabel(ylabel=feature_ylabel, fontsize=8)\n",
    "    axes[i,1].set(xlabel='')\n",
    "    for p in (0, 1, 2):\n",
    "        y = temporal_features_nonorm[temporal_features_nonorm['Label']==str(p)][feature].dropna()\n",
    "        x = np.random.normal(p, 0.04, size=len(y))\n",
    "        axes[i,1].plot(x, y, 'r.', alpha=0.2)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "feature_names = spectral_features.drop(['Channel', 'Label'], axis=1).columns.tolist()\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "# Make plot for each feature\n",
    "fig, axes = plt.subplots(ncols=2, nrows=len(feature_names), figsize=(16,9))\n",
    "plt.rcParams.update({'font.size': 6})\n",
    "for i,feature in enumerate(feature_names):\n",
    "    axes[i,0] = sns.boxplot(x='Label', y=feature, palette='Set2', data=spectral_features, ax=axes[i,0])\n",
    "    feature_ylabel = re.sub(r'(:)', r'\\1\\n', feature)\n",
    "    axes[i,0].set_ylabel(ylabel=feature_ylabel, fontsize=8)\n",
    "    axes[i,0].set(xlabel='')\n",
    "    for p in (0, 1, 2):\n",
    "        y = spectral_features[spectral_features['Label']==str(p)][feature].dropna()\n",
    "        x = np.random.normal(p, 0.04, size=len(y))\n",
    "        axes[i,0].plot(x, y, 'r.', alpha=0.2)\n",
    "    \n",
    "    axes[i,1] = sns.boxplot(x='Label', y=feature, palette='Set2', data=spectral_features_nonorm, ax=axes[i,1])\n",
    "    feature_ylabel = re.sub(r'(:)', r'\\1\\n', feature)\n",
    "    axes[i,1].set_ylabel(ylabel=feature_ylabel, fontsize=8)\n",
    "    axes[i,1].set(xlabel='')\n",
    "    for p in (0, 1, 2):\n",
    "        y = spectral_features_nonorm[spectral_features_nonorm['Label']==str(p)][feature].dropna()\n",
    "        x = np.random.normal(p, 0.04, size=len(y))\n",
    "        axes[i,1].plot(x, y, 'r.', alpha=0.2)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "feature_names = hand_engineered_features.drop(['Channel', 'Label'], axis=1).columns.tolist()\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "# Make plot for each feature\n",
    "plt.rcParams.update({'font.size': 6})\n",
    "for i,feature in enumerate(feature_names):\n",
    "    fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(16,9))\n",
    "    axes[0] = sns.boxplot(x='Label', y=feature, palette='Set2', data=hand_engineered_features, ax=axes[0])\n",
    "    feature_ylabel = re.sub(r'(:)', r'\\1\\n', feature)\n",
    "    axes[0].set_ylabel(ylabel=feature_ylabel, fontsize=8)\n",
    "    axes[0].set(xlabel='')\n",
    "    for p in (0, 1, 2):\n",
    "        y = hand_engineered_features[hand_engineered_features['Label']==str(p)][feature].dropna()\n",
    "        x = np.random.normal(p, 0.04, size=len(y))\n",
    "        axes[0].plot(x, y, 'r.', alpha=0.2)\n",
    "    \n",
    "    axes[1] = sns.boxplot(x='Label', y=feature, palette='Set2', data=hand_engineered_features_nonorm, ax=axes[1])\n",
    "    feature_ylabel = re.sub(r'(:)', r'\\1\\n', feature)\n",
    "    axes[1].set_ylabel(ylabel=feature_ylabel, fontsize=8)\n",
    "    axes[1].set(xlabel='')\n",
    "    for p in (0, 1, 2):\n",
    "        y = hand_engineered_features_nonorm[hand_engineered_features_nonorm['Label']==str(p)][feature].dropna()\n",
    "        x = np.random.normal(p, 0.04, size=len(y))\n",
    "        axes[1].plot(x, y, 'r.', alpha=0.2)\n",
    "        \n",
    "    plt.draw()\n",
    "    plt.waitforbuttonpress()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Between Features and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_ratio(categories, measurements):\n",
    "    fcat, _ = pd.factorize(categories)\n",
    "    cat_num = np.max(fcat)+1\n",
    "    y_avg_array = np.zeros(cat_num)\n",
    "    n_array = np.zeros(cat_num)\n",
    "    for i in range(0,cat_num):\n",
    "        cat_measures = measurements[np.argwhere(fcat == i).flatten()]\n",
    "        n_array[i] = len(cat_measures)\n",
    "        y_avg_array[i] = np.average(cat_measures)\n",
    "    y_total_avg = np.sum(np.multiply(y_avg_array,n_array))/np.sum(n_array)\n",
    "    numerator = np.sum(np.multiply(n_array,np.power(np.subtract(y_avg_array,y_total_avg),2)))\n",
    "    denominator = np.sum(np.power(np.subtract(measurements,y_total_avg),2))\n",
    "    if numerator == 0:\n",
    "        eta = 0.0\n",
    "    else:\n",
    "        eta = numerator/denominator\n",
    "    return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal Features\n",
      "\n",
      "Approximate Entropy: m=3 r=0.7: \n",
      "0.23531762597696576\n",
      "Energy Ratio by Chunks: num_segments=10 segment_focus=2: \n",
      "0.006561813976145857\n",
      "Energy Ratio by Chunks: num_segments=10 segment_focus=3: \n",
      "0.022128593397454745\n",
      "Index Mass Quantile: q=0.4: \n",
      "0.12484643817214154\n",
      "Index Mass Quantile: q=0.6: \n",
      "0.14200936919564663\n",
      "Maximum Absolute Value: \n",
      "0.012078767067050808\n",
      "Ratio Beyond 1xSTD: \n",
      "0.14106703968612852\n",
      "\n",
      " Spectral Features\n",
      "\n",
      "Power Spectral Entropy: \n",
      "nan\n",
      "Power Spectral Entropy Around Maximum Energy: width=60: \n",
      "0.004669478111697543\n",
      "Spectral Centroid: \n",
      "0.0017868944358547217\n",
      "Spectral Centroid Around Maximum Energy: width=60: \n",
      "0.0013636814429217\n",
      "\n",
      " Hand Engineered Features\n",
      "\n",
      "Conduction Delay: set_thresh=False: \n",
      "0.08127395732253252\n",
      "Energy Around Max Energy: \n",
      "0.0008168402358414893\n",
      "Location of Maximum Energy: M=14: \n",
      "0.12415559866072236\n",
      "Number of Peaks: set_thresh=False: \n",
      "0.24110149079797785\n",
      "Number of Peaks: set_thresh=True: \n",
      "0.10215937669754108\n",
      "Peaks Between Min and Max: \n",
      "0.03791395094971498\n",
      "Percentage Fractionation: thresh=0.01: \n",
      "0.15146831765916252\n",
      "Sample Entropy Around Max Energy: width=30 r=0.15 m=3: \n",
      "0.1915523698447314\n",
      "Width of Maximum Energy: M=14, width_thresh=0.2: \n",
      "0.2198513963309588\n",
      "\n",
      " DTW Distance\n",
      "0.16264799170823235\n"
     ]
    }
   ],
   "source": [
    "feature_names = temporal_features.drop(['Channel', 'Label'], axis=1).columns\n",
    "print('Temporal Features\\n')\n",
    "for feature in feature_names:\n",
    "    label = (temporal_features['Label']=='2').astype(int)\n",
    "    feature_values = temporal_features[feature].values\n",
    "    eta = correlation_ratio(label, feature_values)\n",
    "    print(feature + ': ')\n",
    "    print(eta)\n",
    "\n",
    "print('\\n Spectral Features\\n')\n",
    "feature_names = spectral_features.drop(['Channel', 'Label'], axis=1).columns\n",
    "for feature in feature_names:\n",
    "    label = (spectral_features['Label']=='2').astype(int)\n",
    "    feature_values = spectral_features[feature].values\n",
    "    eta = correlation_ratio(label, feature_values)\n",
    "    print(feature + ': ')\n",
    "    print(eta)\n",
    "    \n",
    "print('\\n Hand Engineered Features\\n')\n",
    "feature_names = hand_engineered_features.drop(['Channel', 'Label'], axis=1).columns\n",
    "for feature in feature_names:\n",
    "    label = (hand_engineered_features['Label']=='2').astype(int)\n",
    "    feature_values = hand_engineered_features[feature].values\n",
    "    eta = correlation_ratio(label, feature_values)\n",
    "    print(feature + ': ')\n",
    "    print(eta)\n",
    "    \n",
    "print('\\n DTW Distance')\n",
    "feature_values = dtw_df['DTW Distance'].values\n",
    "eta = correlation_ratio(label, feature_values)\n",
    "print(eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots of Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# fig = plt.figure(figsize=(8,4))\n",
    "# ax = sns.boxplot(x='Label', y='Ratio Beyond 1xSTD', palette=['g', 'orange', 'r'], data=temporal_features)\n",
    "# feature_ylabel = re.sub(r'(:)', r'\\1\\n', 'Ratio Above 1xSTD')\n",
    "# # ax.set_ylabel(ylabel=feature_ylabel, fontsize=8)\n",
    "# ax.set(xlabel='')\n",
    "# ax.set(xticks=[])\n",
    "# ax.set(ylabel='')\n",
    "# for p in (0, 1, 2):\n",
    "#     y = temporal_features[temporal_features['Label']==str(p)]['Ratio Beyond 1xSTD'].dropna()\n",
    "#     x = np.random.normal(p, 0.04, size=len(y))\n",
    "#     ax.plot(x, y, 'k.', alpha=0.2)\n",
    "    \n",
    "# plt.title('Ratio Above $\\sigma$', fontsize=16)\n",
    "# plt.yticks(fontsize=14)\n",
    "# plt.draw()\n",
    "# plt.waitforbuttonpress()\n",
    "# plt.close()\n",
    "\n",
    "# feature_names = hand_engineered_features.drop(['Channel', 'Label'], axis=1).columns\n",
    "# feature_titles = ('Conduction Delay', 'Energy Around Max Energy', 'Location of Maximum Energy', \n",
    "#                   'Number of Peaks', 'Number of Peaks Bad', 'Peaks Between Min/Max', 'Percentage Fractionation',\n",
    "#                  'Sample Entropy', 'Width of Max Energy')\n",
    "# for feature, feature_title in zip(feature_names, feature_titles):\n",
    "#     fig = plt.figure(figsize=(8,4))\n",
    "#     ax = sns.boxplot(x='Label', y=feature, palette=['g', 'orange', 'r'], data=hand_engineered_features)\n",
    "#     ax.set(xlabel='')\n",
    "#     ax.set(xticks=[])\n",
    "#     ax.set(ylabel='')\n",
    "#     for p in (0, 1, 2):\n",
    "#         y = hand_engineered_features[hand_engineered_features['Label']==str(p)][feature].dropna()\n",
    "#         x = np.random.normal(p, 0.04, size=len(y))\n",
    "#         ax.plot(x, y, 'k.', alpha=0.2)\n",
    "\n",
    "#     plt.title(feature_title, fontsize=16)\n",
    "#     plt.yticks(fontsize=14)\n",
    "#     plt.draw()\n",
    "#     plt.waitforbuttonpress()\n",
    "#     plt.close()\n",
    "    \n",
    "fig = plt.figure(figsize=(8,4))\n",
    "ax = sns.boxplot(x='Label', y='DTW Distance', palette=['g', 'orange', 'r'], data=dtw_df)\n",
    "feature_ylabel = re.sub(r'(:)', r'\\1\\n', 'Ratio Above 1xSTD')\n",
    "# ax.set_ylabel(ylabel=feature_ylabel, fontsize=8)\n",
    "ax.set(xlabel='')\n",
    "ax.set(xticks=[])\n",
    "ax.set(ylabel='')\n",
    "for p in (0, 1, 2):\n",
    "    y = dtw_df[dtw_df['Label']==str(p)]['DTW Distance'].dropna()\n",
    "    x = np.random.normal(p, 0.04, size=len(y))\n",
    "    ax.plot(x, y, 'k.', alpha=0.2)\n",
    "    \n",
    "plt.title('DTW Distance', fontsize=16)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.draw()\n",
    "plt.waitforbuttonpress()\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "ax = sns.boxplot(x='Label', y='Normalised Mean', palette=['g', 'orange', 'r'], data=hand_picked_features)\n",
    "# ax.set_ylabel(ylabel=feature_ylabel, fontsize=8)\n",
    "ax.set(xlabel='')\n",
    "ax.set(xticks=[])\n",
    "ax.set(ylabel='')\n",
    "for p in (0, 1, 2):\n",
    "    y = hand_picked_features[hand_picked_features['Label']==str(p)]['Normalised Mean'].dropna()\n",
    "    x = np.random.normal(p, 0.04, size=len(y))\n",
    "    ax.plot(x, y, 'k.', alpha=0.2)\n",
    "    \n",
    "plt.title('Mean Absolute Value', fontsize=16)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.draw()\n",
    "plt.waitforbuttonpress()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Specific Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Extracting Features: 100.0%'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hand_picked_feature_list = []\n",
    "dtw_list = []\n",
    "\n",
    "for i,row in X_S2.iterrows():\n",
    "    clear_output(wait=True)\n",
    "    display('Extracting Features: ' + str(round((i/X_S2.index[-1])*100, 3)) + '%')\n",
    "    \n",
    "    # Get the patients response to the first S1 stimuli as the reference response\n",
    "    # Get typical response for this patient and channel\n",
    "    # Bad apples\n",
    "    if (((row['Type'] + row['Patient']) == 'af8') & (row['Channel'] == 'CS5-6')):\n",
    "        typical_response = X_S1[(X_S1['Type']==row['Type']) & \n",
    "                           (X_S1['Patient']==row['Patient']) &\n",
    "                           (X_S1['Channel']==row['Channel'])\n",
    "                           ].sort_values(by=['Coupling Interval'], ascending=False).iloc[2]\n",
    "    elif (((row['Type'] + row['Patient']) == 'at1') & (row['Channel'] == 'CS1-2')):\n",
    "        typical_response = X_S1[(X_S1['Type']==row['Type']) & \n",
    "                           (X_S1['Patient']==row['Patient']) &\n",
    "                           (X_S1['Channel']==row['Channel'])\n",
    "                           ].sort_values(by=['Coupling Interval'], ascending=False).iloc[4]\n",
    "    else:\n",
    "        typical_response = X_S1[(X_S1['Type']==row['Type']) & \n",
    "                               (X_S1['Patient']==row['Patient']) &\n",
    "                               (X_S1['Channel']==row['Channel'])\n",
    "                               ].sort_values(by=['Coupling Interval'], ascending=False).iloc[0]\n",
    "        \n",
    "    # Normalise amplitudes with respect to the typical response amplitude.\n",
    "    s1_response = typical_response['Data']/max(abs(typical_response['Data']))\n",
    "    s2_response = row['Data']/max(abs(typical_response['Data']))\n",
    "    \n",
    "    ref_hand_picked_feature_dict = get_hand_picked_feature_dict(s1_response, col_prefix = '')\n",
    "    hand_picked_feature_dict = get_hand_picked_feature_dict(s2_response, col_prefix = '')\n",
    "\n",
    "    \n",
    "    for k, v in hand_picked_feature_dict.items():\n",
    "        hand_picked_feature_dict[k] = v - ref_hand_picked_feature_dict[k]\n",
    "        \n",
    "    hand_picked_feature_dict['Label'] = row['Label']\n",
    "    hand_picked_feature_dict['Channel'] = row['Channel']\n",
    "    \n",
    "#     fdtw = fastdtw.dtw(s2_response, s1_response)\n",
    "#     dtw_dict = {}\n",
    "#     dtw_dict['DTW Distance'] = fdtw[0]\n",
    "#     dtw_dict['Label'] = row['Label']\n",
    "#     dtw_dict['Channel'] = row['Channel']\n",
    "    \n",
    "    hand_picked_feature_list.append(hand_picked_feature_dict)\n",
    "#     dtw_list.append(dtw_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_picked_features = pd.DataFrame(hand_picked_feature_list)\n",
    "# dtw_df = pd.DataFrame(dtw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "feature_names = hand_picked_features.drop(['Channel', 'Label'], axis=1).columns\n",
    "feature_names = feature_names.tolist()\n",
    "feature_names.append(feature_names[0])\n",
    "sns.set(style=\"whitegrid\")\n",
    "# Make plot for each feature\n",
    "fig, axes = plt.subplots(ncols=2, nrows=math.ceil(len(feature_names)/2), figsize=(16,9))\n",
    "plt.rcParams.update({'font.size': 6})\n",
    "for i,feature in enumerate(feature_names):\n",
    "    if (i < math.ceil(len(feature_names)/2)):\n",
    "        axes[i,0] = sns.boxplot(x='Label', y=feature, palette='Set2', data=hand_picked_features, ax=axes[i,0])\n",
    "        feature_ylabel = re.sub(r'(:)', r'\\1\\n', feature)\n",
    "        axes[i,0].set_ylabel(ylabel=feature_ylabel, fontsize=8)\n",
    "        axes[i,0].set(xlabel='')\n",
    "        for p in (0, 1, 2):\n",
    "            y = hand_picked_features[hand_picked_features['Label']==str(p)][feature].dropna()\n",
    "            x = np.random.normal(p, 0.04, size=len(y))\n",
    "            axes[i,0].plot(x, y, 'r.', alpha=0.2)\n",
    "    else:\n",
    "        j = i - math.ceil(len(feature_names)/2)\n",
    "        axes[j,1] = sns.boxplot(x='Label', y=feature, palette='Set2', data=hand_picked_features, ax=axes[j,1])\n",
    "        feature_ylabel = re.sub(r'(:)', r'\\1\\n', feature)\n",
    "        axes[j,1].set_ylabel(ylabel=feature_ylabel, fontsize=8)\n",
    "        axes[j,1].set(xlabel='')\n",
    "        for p in (0, 1, 2):\n",
    "            y = hand_picked_features[hand_picked_features['Label']==str(p)][feature].dropna()\n",
    "            x = np.random.normal(p, 0.04, size=len(y))\n",
    "            axes[j,1].plot(x, y, 'r.', alpha=0.2)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Hand Picked Features\n",
      "\n",
      "Mean: \n",
      "0.006447794931599672\n",
      "Normalised Mean: \n",
      "0.09547942250217417\n"
     ]
    }
   ],
   "source": [
    "print('\\n Hand Picked Features\\n')\n",
    "feature_names = hand_picked_features.drop(['Channel', 'Label'], axis=1).columns\n",
    "for feature in feature_names:\n",
    "    label = (hand_picked_features['Label']=='2').astype(int)\n",
    "    feature_values = hand_picked_features[feature].values\n",
    "    eta = correlation_ratio(label, feature_values)\n",
    "    print(feature + ': ')\n",
    "    print(eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "sns.boxplot(x='Label', y='DTW Distance', palette='Set2', data=dtw_df)\n",
    "ylabel = re.sub(r'(:)', r'\\1\\n', 'DTW Distance')\n",
    "plt.ylabel(ylabel, fontsize=8)\n",
    "plt.xlabel('')\n",
    "for p in (0, 1, 2):\n",
    "    y = dtw_df[dtw_df['Label']==str(p)]['DTW Distance'].dropna()\n",
    "    x = np.random.normal(p, 0.04, size=len(y))\n",
    "    plt.plot(x, y, 'r.', alpha=0.2)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A shitty conduction delay detector\n",
    "def get_delay(x, amp_thresh=None, set_thresh=False):\n",
    "    if (set_thresh==True):\n",
    "        if any(abs(x)>amp_thresh):\n",
    "            return np.argmax(abs(x)>amp_thresh)\n",
    "        else:\n",
    "            return len(x)\n",
    "    else:    \n",
    "        return np.argmax(abs(x)>(max(abs(x))/2))\n",
    "    \n",
    "def denoise(x):\n",
    "    # Obtain Daubechies N=6 wavelet coefficients\n",
    "    waveletCoefs = pywt.wavedec(x, 'db7', mode='per')\n",
    "\n",
    "    # Throw away coefficients corresponding to noise\n",
    "    sigma = mad(waveletCoefs[-1])\n",
    "    uThresh = 1*sigma*np.sqrt(2*np.log(len(x)))\n",
    "    denoised = waveletCoefs[:]\n",
    "    denoised[1:] = (pywt._thresholding.hard(i, value=uThresh) for i in denoised[1:])\n",
    "\n",
    "    # Reconstruct the original signal\n",
    "    xDenoised = pywt.waverec(denoised, 'db7', mode='per')\n",
    "\n",
    "    return xDenoised\n",
    "\n",
    "def get_peaks(x, height_thresh, scale_amp=None, set_scale=False, plot = False):\n",
    "    x = np.array(x)\n",
    "    \n",
    "    # Get height_thresh\n",
    "    if set_scale:\n",
    "        height_thresh = height_thresh*scale_amp\n",
    "    else:\n",
    "        height_thresh = height_thresh*max(abs(x))\n",
    "    \n",
    "    # Denoise x\n",
    "    xdn = denoise(x)\n",
    "\n",
    "    # Detect peaks using detect_peaks\n",
    "    pos_peak_idx = detect_peaks(xdn, mph=height_thresh, threshold = 0)\n",
    "    neg_peak_idx = detect_peaks((-xdn), mph=height_thresh, threshold = 0)\n",
    "    peak_idx = np.concatenate([pos_peak_idx, neg_peak_idx])\n",
    "    peak_idx = np.sort(peak_idx)\n",
    "    # Edge indeces aren't detected\n",
    "    peak_idx = peak_idx[(peak_idx != 0) & (peak_idx != (len(xdn)-1))]\n",
    "\n",
    "    new_peak_idx = []\n",
    "    peak_amp = []\n",
    "    if (len(peak_idx) > 0):\n",
    "        new_peak_idx.append(peak_idx[0])\n",
    "        mp_thresh = 0.2*max(abs(x))\n",
    "        for i in range(len(peak_idx)-1):\n",
    "            idx = peak_idx[i]\n",
    "            idx_next = peak_idx[i+1]\n",
    "            mid_point = int((idx_next+idx)/2)\n",
    "            if (max([abs(x[idx_next]-x[mid_point]), abs(x[idx]-x[mid_point])]) > mp_thresh):\n",
    "                new_peak_idx.append(idx_next)\n",
    "\n",
    "        peak_idx = np.array(new_peak_idx)\n",
    "        peak_amp = x[peak_idx]\n",
    "\n",
    "    if plot == True:\n",
    "        fig, [ax1] = plt.subplots(nrows=1, ncols=1, sharex=True, figsize=(8,8))\n",
    "        ax1.plot(x, 'b' , xdn, 'r--', peak_idx, peak_amp, 'kx')\n",
    "        #plt.title(fileName)\n",
    "        ax1.set_xlabel('Sample')\n",
    "        ax1.set_ylabel('Normalised amplitude')\n",
    "        ax1.legend(['Original segment', 'Denoised segment', 'Detected peaks'])\n",
    "\n",
    "        plt.draw()\n",
    "        plt.waitforbuttonpress(0) # this will wait for indefinite time\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "    return peak_idx, peak_amp\n",
    "\n",
    "def sample_entropy(U, m, r):\n",
    "\n",
    "    def _maxdist(x_i, x_j):\n",
    "        result = max([abs(ua-va) for ua, va in zip(x_i, x_j)])\n",
    "        return result\n",
    "\n",
    "    def _phi(m):\n",
    "        x = np.zeros([N,m-1])\n",
    "        for i in range(N-m+1):\n",
    "            x[i,:] = U[i:i+m-1]\n",
    "\n",
    "        C = 0\n",
    "        for i in range(len(x)):\n",
    "            for j in range(len(x)):\n",
    "                if i != j:\n",
    "                    if _maxdist(x[i,:], x[j,:]) <= r:\n",
    "                        C = C + 1\n",
    "\n",
    "        return C\n",
    "\n",
    "    U = U/max(abs(U))\n",
    "    N = len(U)\n",
    "\n",
    "    return -np.log(_phi(m+1)/_phi(m))\n",
    "\n",
    "def percentage_fractionation(x, peak_idxs, thresh=0.01, sr=1000):\n",
    "    # Get peak indexes and amplitude\n",
    "    peak_idx_diffs = np.diff(peak_idxs)\n",
    "    frac_time = 0\n",
    "    frac_time = np.sum(peak_idx_diffs[peak_idx_diffs < thresh*sr])\n",
    "    prcnt_frac = (frac_time/len(x))*100\n",
    "    return prcnt_frac\n",
    "\n",
    "def get_local_sample_entropy(x, centre_idx, width, m=2, r=0.05):\n",
    "    # Ensure width is odd\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return sample_entropy(x[:width+1], m, r)\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return sample_entropy(x[len(x)-1-width:], m, r)\n",
    "    else:\n",
    "        return sample_entropy(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)], m, r)\n",
    "    \n",
    "def get_location_of_max_energy(x, M=14):\n",
    "    v = np.ones(M)\n",
    "    x_ = np.convolve(abs(x), v)\n",
    "    return (np.argmax(x_) + math.floor(M/2))\n",
    "        \n",
    "def get_local_peaks(x, centre_idx, width=25, height_thresh=0.1):\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return get_peaks(x[:width+1], height_thresh)\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return get_peaks(x[len(x)-1-width:], height_thresh)\n",
    "    else:\n",
    "        return get_peaks(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)], height_thresh)\n",
    "    \n",
    "def get_pse(x):\n",
    "    x_fft = np.fft.rfft(x)\n",
    "    x_P = (1/len(x_fft))*np.absolute(x_fft)**2\n",
    "    x_p = x_P/sum(x_P)\n",
    "    pse = np.sum([(-p*np.log2(p)) for p in x_p])\n",
    "    return pse\n",
    "\n",
    "def get_local_pse(x, centre_idx, width=50):\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return get_pse(x[:width+1])\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return get_pse(x[len(x)-1-width:])\n",
    "    else:\n",
    "        return get_pse(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)])\n",
    "    \n",
    "def get_spectral_centroid(x):\n",
    "    x_fft = np.fft.rfft(x)\n",
    "    x_spectrum = np.absolute(x_fft)\n",
    "    normalized_spectrum = x_spectrum/sum(x_spectrum)\n",
    "    normalized_frequencies = np.arange(0, len(x_spectrum), 1)\n",
    "    return sum(normalized_frequencies * normalized_spectrum)\n",
    "\n",
    "def get_local_spectral_centroid(x, centre_idx, width=50):\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return get_spectral_centroid(x[:width+1])\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return get_spectral_centroid(x[len(x)-1-width:])\n",
    "    else:\n",
    "        return get_spectral_centroid(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)])\n",
    "    \n",
    "def get_local_energy(x, centre_idx, width=60):\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return np.sum(x[:width+1]**2)\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return np.sum(x[len(x)-1-width:]**2)\n",
    "    else:\n",
    "        return np.sum(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)]**2)\n",
    "    \n",
    "def get_width_max_energy(x, M=14, width_thresh=0.2):\n",
    "    v = np.ones(M)\n",
    "    x_ = np.convolve(abs(x), v)\n",
    "    if any(x_[np.argmax(x_):] < width_thresh*np.max(x_)):\n",
    "        end_idx = np.argmax(x_) + np.argmax(x_[np.argmax(x_):] < width_thresh*np.max(x_))\n",
    "    else:\n",
    "        end_idx = len(x_)-1\n",
    "    if any(x_[np.argmax(x_)::-1] < width_thresh*np.max(x_)):  \n",
    "        start_idx = np.argmax(x_) - np.argmax(x_[np.argmax(x_)::-1] < width_thresh*np.max(x_))\n",
    "    else:\n",
    "        start_idx = 0\n",
    "\n",
    "    return (end_idx - start_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hand_picked_feature_dict(x, col_prefix=''):\n",
    "    feature_dict = {}\n",
    "    \n",
    "    feature_dict[col_prefix + 'Mean'] = np.mean(abs(x))\n",
    "    feature_dict[col_prefix + 'Normalised Mean'] = np.mean(abs(x)/max(abs(x)))\n",
    "    \n",
    "    return feature_dict\n",
    "\n",
    "def get_hand_engineered_feature_dict(x, col_prefix = ''):\n",
    "    feature_dict = {}\n",
    "    # Hand engineered features\n",
    "    \n",
    "    min_idx = np.argmin(x)\n",
    "    max_idx = np.argmax(x)\n",
    "    \n",
    "    height_thresh=0.1\n",
    "    peaks = get_peaks(x, height_thresh)\n",
    "    feature_dict[col_prefix + 'Number of Peaks: thresh=0.1'] = len(peaks[0])\n",
    "    feature_dict[col_prefix + 'Percentage Fractionation: thresh=0.1'] = percentage_fractionation(x, peaks[0], thresh=0.01)\n",
    "    feature_dict[col_prefix + 'Peaks Between Min and Max: thresh=0.1'] = len([i for i in peaks[0] if ((i > min_idx) & (i < max_idx))])\n",
    "    \n",
    "    height_thresh=0.2\n",
    "    peaks = get_peaks(x, height_thresh)\n",
    "    feature_dict[col_prefix + 'Number of Peaks: thresh=0.2'] = len(peaks[0])\n",
    "    feature_dict[col_prefix + 'Percentage Fractionation: thresh=0.2'] = percentage_fractionation(x, peaks[0], thresh=0.01)\n",
    "    feature_dict[col_prefix + 'Peaks Between Min and Max: thresh=0.2'] = len([i for i in peaks[0] if ((i > min_idx) & (i < max_idx))])\n",
    "\n",
    "    \n",
    "    max_energy_idx = get_location_of_max_energy(x, M=14)\n",
    "    feature_dict[col_prefix + 'Location of Maximum Energy: M=14'] = max_energy_idx\n",
    "    max_energy_idx = get_location_of_max_energy(x, M=10)\n",
    "    feature_dict[col_prefix + 'Location of Maximum Energy: M=10'] = max_energy_idx\n",
    "    \n",
    "#     feature_dict[col_prefix + 'Sample Entropy Around Max Energy: width=30 r=0.15 m=3'] = get_local_sample_entropy(x, max_energy_idx, 60, m=3, r=0.15)\n",
    "    \n",
    "    feature_dict[col_prefix + 'Width of Maximum Energy: M=14, width_thresh=0.2'] = get_width_max_energy(x, M=14, width_thresh=0.2)\n",
    "\n",
    "    return feature_dict\n",
    "\n",
    "def get_spectral_feature_dict(x, col_prefix = ''):\n",
    "    feature_dict = {}\n",
    "    feature_dict[col_prefix + 'Power Spectral Entropy'] = get_pse(x)\n",
    "    feature_dict[col_prefix + 'Spectral Centroid'] = get_spectral_centroid(x)\n",
    "    max_energy_idx = get_location_of_max_energy(x)\n",
    "    feature_dict[col_prefix + 'Power Spectral Entropy Around Maximum Energy: width=60'] = get_local_pse(x, max_energy_idx, width=60)\n",
    "    feature_dict[col_prefix + 'Spectral Centroid Around Maximum Energy: width=60'] = get_local_spectral_centroid(x, max_energy_idx, width=60)\n",
    "    \n",
    "    return feature_dict\n",
    "    \n",
    "def get_temporal_feature_dict(x, col_prefix = ''):\n",
    "\n",
    "    feature_dict = {}\n",
    "    feature_dict[col_prefix + 'Maximum Absolute Value'] = np.max(abs(x))\n",
    "    \n",
    "#     feature_dict[col_prefix + 'Approximate Entropy: m=3 r=0.7'] = feature_calculators.approximate_entropy(x, 3, 0.7)\n",
    "    feature_dict[col_prefix + 'Ratio Beyond 1xSTD'] = feature_calculators.ratio_beyond_r_sigma(x, 1)\n",
    "    # A fraction q of the mass lies to the left of i. (Alternative to conduction delay?)\n",
    "    \n",
    "\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
